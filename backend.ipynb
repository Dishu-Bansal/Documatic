{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f18883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in d:\\special\\documatic\\.venv\\lib\\site-packages (3.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: flask-sqlalchemy in d:\\special\\documatic\\.venv\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: flask-session in d:\\special\\documatic\\.venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: flask-login in d:\\special\\documatic\\.venv\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: torchvision in d:\\special\\documatic\\.venv\\lib\\site-packages (0.20.1+cu118)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.16 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask-sqlalchemy) (2.0.36)\n",
      "Requirement already satisfied: msgspec>=0.18.6 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask-session) (0.18.6)\n",
      "Requirement already satisfied: cachelib in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask-session) (0.13.0)\n",
      "Requirement already satisfied: numpy in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: torch==2.5.1+cu118 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (2.5.1+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.5.1+cu118->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.5.1+cu118->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.5.1+cu118->torchvision) (3.4.2)\n",
      "Requirement already satisfied: fsspec in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.5.1+cu118->torchvision) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.5.1+cu118->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1+cu118->torchvision) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\special\\documatic\\.venv\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sqlalchemy>=2.0.16->flask-sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: qwen-vl-utils in d:\\special\\documatic\\.venv\\lib\\site-packages (0.0.8)\n",
      "Requirement already satisfied: transformers in d:\\special\\documatic\\.venv\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: accelerate in d:\\special\\documatic\\.venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: pdf2image in d:\\special\\documatic\\.venv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: av in d:\\special\\documatic\\.venv\\lib\\site-packages (from qwen-vl-utils) (14.0.1)\n",
      "Requirement already satisfied: packaging in d:\\special\\documatic\\.venv\\lib\\site-packages (from qwen-vl-utils) (24.2)\n",
      "Requirement already satisfied: pillow in d:\\special\\documatic\\.venv\\lib\\site-packages (from qwen-vl-utils) (11.0.0)\n",
      "Requirement already satisfied: requests in d:\\special\\documatic\\.venv\\lib\\site-packages (from qwen-vl-utils) (2.32.3)\n",
      "Requirement already satisfied: filelock in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in d:\\special\\documatic\\.venv\\lib\\site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from accelerate) (2.5.1+cu118)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\special\\documatic\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->qwen-vl-utils) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->qwen-vl-utils) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->qwen-vl-utils) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->qwen-vl-utils) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: faiss-cpu in d:\\special\\documatic\\.venv\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in d:\\special\\documatic\\.venv\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: numpy in d:\\special\\documatic\\.venv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: packaging in d:\\special\\documatic\\.venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (2.5.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (1.6.0)\n",
      "Requirement already satisfied: scipy in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\special\\documatic\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting flask\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting Werkzeug>=3.1 (from flask)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Jinja2>=3.1.2 (from flask)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting itsdangerous>=2.2 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting blinker>=1.9 (from flask)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting colorama (from click>=8.1.3->flask)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: MarkupSafe, itsdangerous, colorama, blinker, Werkzeug, Jinja2, click, flask\n",
      "Successfully installed Jinja2-3.1.5 MarkupSafe-3.0.2 Werkzeug-3.1.3 blinker-1.9.0 click-8.1.8 colorama-0.4.6 flask-3.1.0 itsdangerous-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in d:\\special\\documatic\\.venv\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in d:\\special\\documatic\\.venv\\lib\\site-packages (0.20.1+cu118)\n",
      "Requirement already satisfied: torchaudio in d:\\special\\documatic\\.venv\\lib\\site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: filelock in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install flask flask-sqlalchemy flask-session flask-login torchvision\n",
    "%pip install qwen-vl-utils transformers accelerate pdf2image\n",
    "%pip install faiss-cpu sentence-transformers numpy\n",
    "%pip install --ignore-installed flask\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !apt update\n",
    "# !apt install poppler-utils -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139a497d-f336-471a-bffb-16a14d77f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from accelerate import Accelerator\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "# from llm_axe.agents import OnlineAgent\n",
    "from pathlib import Path\n",
    "import os\n",
    "from flask import Flask, request, jsonify, send_file, abort\n",
    "from werkzeug.utils import secure_filename\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39ee8cb-717b-4fd2-853d-5e5fe3565a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2289d5fe-852f-4715-b10a-363696b750e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4013fa0e245b442c9df571ba916aac4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default: Load the model on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=\"float16\", device_map={\"\": device}#, load_in_8bit=True\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "\n",
    "# The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed740a8b-e87f-4e69-81da-07460bdef987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLiteFileSummaryStorage:\n",
    "    \"\"\"Store file summaries using SQLite\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path=\"file_summaries.db\"):\n",
    "        self.db_path = db_path\n",
    "        self._ensure_database_exists()\n",
    "    \n",
    "    def _ensure_database_exists(self):\n",
    "        \"\"\"Create database and table if they don't exist\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS file_summaries (\n",
    "                filename TEXT PRIMARY KEY,\n",
    "                filepath TEXT,\n",
    "                summary TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def save_summary(self, filename, filepath, summary):\n",
    "        \"\"\"Save a file summary\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                INSERT OR REPLACE INTO file_summaries (filename, filepath, summary)\n",
    "                VALUES (?, ?, ?)\n",
    "            ''', (filename, filepath, summary))\n",
    "            \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving summary: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_summary(self, filename):\n",
    "        \"\"\"Retrieve a file summary\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                SELECT summary FROM file_summaries\n",
    "                WHERE filename = ?\n",
    "            ''', (filename,))\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "            conn.close()\n",
    "            \n",
    "            return result[0] if result else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving summary: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_all_summaries(self):\n",
    "        \"\"\"Get all stored summaries\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                SELECT filename, filepath, summary, timestamp \n",
    "                FROM file_summaries\n",
    "            ''')\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            conn.close()\n",
    "            \n",
    "            return {row[0]: {\n",
    "                'filepath': row[1],\n",
    "                'summary': row[2],\n",
    "                'timestamp': row[3]\n",
    "            } for row in results}\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving summaries: {e}\")\n",
    "            return {}\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# def main():\n",
    "#     # Example using JSON storage\n",
    "#     json_storage = JSONFileSummaryStorage()\n",
    "    \n",
    "#     # Save some summaries\n",
    "#     json_storage.save_summary(\"document1.pdf\", \"This is a report about quarterly earnings\")\n",
    "#     json_storage.save_summary(\"image1.jpg\", \"A landscape photo of mountains\")\n",
    "    \n",
    "#     # Retrieve a specific summary\n",
    "#     print(json_storage.get_summary(\"document1.pdf\"))\n",
    "    \n",
    "#     # Get all summaries\n",
    "#     print(json_storage.get_all_summaries())\n",
    "    \n",
    "#     # Example using SQLite storage\n",
    "#     sqlite_storage = SQLiteFileSummaryStorage()\n",
    "    \n",
    "#     # Save some summaries\n",
    "#     sqlite_storage.save_summary(\"document1.pdf\", \"This is a report about quarterly earnings\")\n",
    "#     sqlite_storage.save_summary(\"image1.jpg\", \"A landscape photo of mountains\")\n",
    "    \n",
    "#     # Retrieve a specific summary\n",
    "#     print(sqlite_storage.get_summary(\"document1.pdf\"))\n",
    "    \n",
    "#     # Get all summaries\n",
    "#     print(sqlite_storage.get_all_summaries())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44689e5-be1a-469a-b13f-a1ac51481809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path, output_folder):\n",
    "    \n",
    "    for i, page in enumerate(images):\n",
    "        page.save(f\"{output_folder}/page_{i + 1}.png\", \"PNG\")\n",
    "\n",
    "# # Example usage\n",
    "# pdf_to_images(\"example.pdf\", \"output_images_folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ababfcd4-05a5-4533-8719-6b796f9ba227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_format(messages: list[dict]) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if the messages are already in the correct format.\n",
    "    \n",
    "    Correct format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"message text\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Args:\n",
    "        messages (list[dict]): List of message dictionaries to validate\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if format is correct, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(messages, list):\n",
    "            return False\n",
    "            \n",
    "        for message in messages:\n",
    "            # Check if basic structure exists\n",
    "            if not isinstance(message, dict):\n",
    "                return False\n",
    "                \n",
    "            if 'role' not in message or 'content' not in message:\n",
    "                return False\n",
    "                \n",
    "            # Check role\n",
    "            if not isinstance(message['role'], str):\n",
    "                return False\n",
    "                \n",
    "            # Check content structure\n",
    "            content = message['content']\n",
    "            if not isinstance(content, list):\n",
    "                return False\n",
    "                \n",
    "            # Validate each content item\n",
    "            for item in content:\n",
    "                if not isinstance(item, dict):\n",
    "                    return False\n",
    "                    \n",
    "                if 'type' not in item or 'text' not in item:\n",
    "                    return False\n",
    "                    \n",
    "                if item['type'] != 'text':\n",
    "                    return False\n",
    "                    \n",
    "                if not isinstance(item['text'], str):\n",
    "                    return False\n",
    "                    \n",
    "        return True\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def convert_message_format(messages: list[dict]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Converts messages from simple format to the structured format required by the model.\n",
    "    \n",
    "    Input format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"message text\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Output format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"message text\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Args:\n",
    "        messages (list[dict]): List of message dictionaries in simple format\n",
    "        \n",
    "    Returns:\n",
    "        list[dict]: List of message dictionaries in structured format\n",
    "    \"\"\"\n",
    "    converted_messages = []\n",
    "    \n",
    "    for message in messages:\n",
    "        # Handle case where content is already in the correct format\n",
    "        if isinstance(message.get('content'), list):\n",
    "            converted_messages.append(message)\n",
    "            continue\n",
    "            \n",
    "        # Convert simple string content to structured format\n",
    "        converted_message = {\n",
    "            \"role\": message[\"role\"],\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": message[\"content\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        converted_messages.append(converted_message)\n",
    "    \n",
    "    return converted_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84bdf40f-197b-4c47-ba01-f38073469623",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JARVIS():\n",
    "\n",
    "    # Your ask function will always receive a list of prompts\n",
    "    # The prompts are in open ai prompt format\n",
    "    #  example: {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "    # If your model supports json format, use the format parameter to specify that to your model.\n",
    "    def ask(self, messages:list, format:str=\"\", temperature:float=0.8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prompts (list): A list of prompts to ask.\n",
    "            format (str, optional): The format of the response. Use \"json\" for json. Defaults to \"\".\n",
    "            temperature (float, optional): The temperature of the LLM. Defaults to 0.8.\n",
    "        \"\"\"\n",
    "        correct_format = is_correct_format(messages)\n",
    "        if not correct_format:\n",
    "            messages = convert_message_format(messages)\n",
    "        # Preparation for inference\n",
    "        text = processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        \n",
    "        # Inference: Generation of the output\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=1024)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        if not correct_format:\n",
    "            return output_text[0]\n",
    "        return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab6585f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\SPECIAL\\Documatic\\poppler\\Library\n"
     ]
    }
   ],
   "source": [
    "import os, platform, subprocess\n",
    "\n",
    "def add_poppler_to_path():\n",
    "    poppler_dir = os.path.join(os.getcwd(), \"poppler\\\\Library\")\n",
    "    print(poppler_dir)\n",
    "    system = platform.system().lower()\n",
    "    if system == \"windows\":\n",
    "        poppler_bin_dir = os.path.join(poppler_dir, \"bin\") # Poppler DLLs usually in bin folder\n",
    "        # if hasattr(os, \"add_dll_directory\"): # Python 3.8+\n",
    "        #     os.add_dll_directory(poppler_bin_dir)\n",
    "        #     print(\"Here\")\n",
    "        # else:\n",
    "        os.environ[\"PATH\"] = poppler_bin_dir + os.pathsep + os.environ[\"PATH\"]\n",
    "    elif system in (\"linux\", \"darwin\"):\n",
    "        lib_path_var = \"LD_LIBRARY_PATH\" if system == \"linux\" else \"DYLD_LIBRARY_PATH\"\n",
    "        poppler_lib_dir = os.path.join(poppler_dir, system, \"lib\")\n",
    "        if lib_path_var in os.environ:\n",
    "            os.environ[lib_path_var] = poppler_lib_dir + os.pathsep + os.environ[lib_path_var]\n",
    "        else:\n",
    "            os.environ[lib_path_var] = poppler_lib_dir\n",
    "    else:\n",
    "        raise OSError(\"Unsupported operating system\")\n",
    "\n",
    "# Call this function BEFORE importing any libraries that depend on Poppler\n",
    "add_poppler_to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6adc0991-c74e-4dce-93e8-08e3cb614d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "db = SQLiteFileSummaryStorage()\n",
    "def generate_summary(filepath, query):\n",
    "    jarvis = JARVIS()\n",
    "    content = []\n",
    "    if filepath.endswith(\".jpg\") or filepath.endswith(\".jpeg\"):\n",
    "        content.append({\n",
    "            \"type\":\"image\",\n",
    "            \"image\":filepath,\n",
    "            \"resized_height\": 280,\n",
    "            \"resized_width\": 420,\n",
    "        })\n",
    "    else:\n",
    "        images = convert_from_path(filepath)\n",
    "        for i, page in enumerate(images):\n",
    "            content.append({\n",
    "                \"type\":\"image\",\n",
    "                \"image\":page,\n",
    "                \"resized_height\": 280,\n",
    "                \"resized_width\": 420,\n",
    "            })\n",
    "#             You are an advanced document summarization expert with over 15 years of experience in analyzing and summarizing complex documents, including OCR-extracted content. Your expertise lies in creating concise, detailed, and unique summaries that capture the essence of a document while highlighting its distinguishing features. You are skilled at identifying subtle variations between similar documents and ensuring that summaries are tailored to reflect these differences.  \n",
    "# Your task is to generate a comprehensive summary of a document based on the following inputs:  \n",
    "\n",
    "# OCR-extracted content: __________  \n",
    "# User-provided description of the document: __________  \n",
    "# Keywords related to the document: __________  \n",
    "# Additional context or details about the document: __________\n",
    "\n",
    "# The summary should focus on the following:  \n",
    "\n",
    "# A clear and concise overview of the document's content, including its purpose and main themes.  \n",
    "# Highlighting the most important keywords and phrases extracted from the OCR content and user-provided description.  \n",
    "# Identifying any unique or distinguishing features of the document that set it apart from similar files.  \n",
    "# Ensuring that if the same document is submitted twice with slight variations, the summary reflects these differences clearly and meaningfully.\n",
    "\n",
    "# For example, if the document is a research paper on climate change, the summary should include its key findings, methodologies, and any unique data points. If the same paper is resubmitted with updated statistics, the summary should emphasize the changes and their implications.  \n",
    "# Generate the summary in a structured format, ensuring it is both informative and easy to understand.\n",
    "\n",
    "    content.append({\"type\": \"text\", \"text\": f\"\"\"You are a document summarization assistant. Your task is to create a comprehensive, searchable summary of a file based on its contents and provided description. Follow this structured approach:\n",
    "GUIDELINES:\n",
    "\n",
    "Focus on discoverability - include terms users might search for\n",
    "Incorporate both technical and layman's terms\n",
    "Consider different ways users might try to find this document\n",
    "Include crucial context from both the file content and user description\n",
    "Add industry-standard terminology where relevant\n",
    "Consider various use cases and access patterns\n",
    "Maintain factual accuracy while optimizing for searchability\n",
    "\n",
    "Now, analyze the provided file and description to generate a comprehensive summary like this, Do not exceed the numbers mentioned:\n",
    "\n",
    "INPUTS:\n",
    "File: attached pages as images. treat them combined as single file\n",
    "User Description: {query}\n",
    "Generate a summary in the following format:\n",
    "CORE SUMMARY (2-3 sentences):\n",
    "[Provide a clear, concise overview of the main content and purpose of the file]\n",
    "\n",
    "DOCUMENT TYPE & PURPOSE:\n",
    "- Primary Purpose: [Main function/goal of the document]\n",
    "- Document Category: [Report/Specification/Manual/Analysis/etc.]\n",
    "- Target Audience: [Intended readers/users]\n",
    "\n",
    "KEY TOPICS:\n",
    "- [Topic 1]\n",
    "- [Topic 2]\n",
    "- [Topic 3]\n",
    "[List 3-5 main topics covered]\n",
    "\n",
    "REFERENCE CONTEXTS:\n",
    "\"This file would be relevant when looking for...\"\n",
    "- [Scenario 1]\n",
    "- [Scenario 2]\n",
    "- [Scenario 3]\n",
    "[List 3-4 specific use cases or scenarios]\n",
    "\n",
    "ADDITIONAL CONTEXT FROM USER DESCRIPTION:\n",
    "[Integrate any unique insights or context from the user's description that aren't apparent from the file content alone]\n",
    "\n",
    "SEARCH KEYWORDS:\n",
    "[List 8-12 relevant search terms, including:\n",
    "- Common synonyms\n",
    "- Technical terms\n",
    "- Related concepts\n",
    "- Alternative phrasings\n",
    "Separate with commas]\n",
    "\n",
    "\"\"\"})\n",
    "    print(content)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content,\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    output_text = jarvis.ask(messages)\n",
    "    return output_text\n",
    "\n",
    "def get_file(query):\n",
    "    jarvis = JARVIS()\n",
    "    summaries = db.get_all_summaries()\n",
    "    print(len(summaries.items()))\n",
    "    print(query)\n",
    "    scores = \"\"\n",
    "    for filename, data in summaries.items():\n",
    "        summary = data['summary']\n",
    "        path = data['filepath']\n",
    "        print(\"Summary: \" + summary)\n",
    "        print(\"Query: \" + query)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"\"\"You are a document matching expert. Analyze how well a query matches a given summary and provide a single confidence score from 0-100.\n",
    "\n",
    "Scoring Criteria:\n",
    "1. Exact Keyword Matches (40 points max):\n",
    "   - Exact matches of query terms (case-insensitive)\n",
    "   - Multiple occurrences increase score\n",
    "   - Technical/specific terms worth more than common words\n",
    "   - Title/key position matches worth more\n",
    "\n",
    "2. Keyword Variations (30 points max):\n",
    "   - Plurals/singulars (car/cars)\n",
    "   - Common synonyms (vehicle/automobile)\n",
    "   - Word forms (run/running/ran)\n",
    "   - Compound variations (healthcare/health care)\n",
    "\n",
    "3. Semantic Relevance (20 points max):\n",
    "   - Topic and concept alignment\n",
    "   - Context relevance\n",
    "\n",
    "4. Additional Factors (10 points max):\n",
    "   - Term proximity\n",
    "   - Information relevance\n",
    "\n",
    "Query: {query}\n",
    "Summary: {summary}\n",
    "\n",
    "Follow these steps silently:\n",
    "1. Check exact keyword matches\n",
    "2. Find keyword variations\n",
    "3. Assess semantic alignment\n",
    "4. Consider additional factors\n",
    "5. Sum up scores\n",
    "\n",
    "Output only this format:\n",
    "Confidence Score: <0-100>\"\"\"},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        output_text = jarvis.ask(messages)\n",
    "        scores += f\"({filename},{path},{str(output_text[0])})\\n\"\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3851ad07-7d80-453e-8d53-7db6b6a3699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'image', 'image': <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1270x2000 at 0x1F72B08A350>, 'resized_height': 280, 'resized_width': 420}, {'type': 'text', 'text': 'You are a document summarization assistant. Your task is to create a comprehensive, searchable summary of a file based on its contents and provided description. Follow this structured approach:\\nGUIDELINES:\\n\\nFocus on discoverability - include terms users might search for\\nIncorporate both technical and layman\\'s terms\\nConsider different ways users might try to find this document\\nInclude crucial context from both the file content and user description\\nAdd industry-standard terminology where relevant\\nConsider various use cases and access patterns\\nMaintain factual accuracy while optimizing for searchability\\n\\nNow, analyze the provided file and description to generate a comprehensive summary like this, Do not exceed the numbers mentioned:\\n\\nINPUTS:\\nFile: attached pages as images. treat them combined as single file\\nUser Description: My indian driving license\\nGenerate a summary in the following format:\\nCORE SUMMARY (2-3 sentences):\\n[Provide a clear, concise overview of the main content and purpose of the file]\\n\\nDOCUMENT TYPE & PURPOSE:\\n- Primary Purpose: [Main function/goal of the document]\\n- Document Category: [Report/Specification/Manual/Analysis/etc.]\\n- Target Audience: [Intended readers/users]\\n\\nKEY TOPICS:\\n- [Topic 1]\\n- [Topic 2]\\n- [Topic 3]\\n[List 3-5 main topics covered]\\n\\nREFERENCE CONTEXTS:\\n\"This file would be relevant when looking for...\"\\n- [Scenario 1]\\n- [Scenario 2]\\n- [Scenario 3]\\n[List 3-4 specific use cases or scenarios]\\n\\nADDITIONAL CONTEXT FROM USER DESCRIPTION:\\n[Integrate any unique insights or context from the user\\'s description that aren\\'t apparent from the file content alone]\\n\\nSEARCH KEYWORDS:\\n[List 8-12 relevant search terms, including:\\n- Common synonyms\\n- Technical terms\\n- Related concepts\\n- Alternative phrasings\\nSeparate with commas]\\n\\n'}]\n",
      "CORE SUMMARY (2-3 sentences):\n",
      "The file contains a photograph of a person's face, along with their personal information, such as name, address, and date of birth. It also includes a QR code and a signature.\n",
      "\n",
      "DOCUMENT TYPE & PURPOSE:\n",
      "- Primary Purpose: Documenting personal information and verifying identity\n",
      "- Document Category: Personal Identification Document (ID)\n",
      "- Target Audience: Individuals seeking to verify their identity or obtain a document for personal or professional use\n",
      "\n",
      "KEY TOPICS:\n",
      "- Personal Identification\n",
      "- Verification of Identity\n",
      "- Documenting Personal Information\n",
      "\n",
      "REFERENCE CONTEXTS:\n",
      "- This file would be relevant when looking for a personal identification document for verification purposes.\n",
      "- It could be used for various scenarios such as applying for a job, obtaining a driver's license, or verifying identity for travel or other official purposes.\n",
      "\n",
      "ADDITIONAL CONTEXT FROM USER DESCRIPTION:\n",
      "- The document is a standard form used in India for personal identification and verification purposes.\n",
      "\n",
      "SEARCH KEYWORDS:\n",
      "- Personal Identification\n",
      "- Verification of Identity\n",
      "- Documenting Personal Information\n"
     ]
    }
   ],
   "source": [
    "summary = generate_summary(\"d:/SPECIAL/Documatic/Indian License.pdf\", \"My indian driving license\")\n",
    "print(summary)\n",
    "# db.save_summary(\"Indian License.pdf\", \"Indian License.pdf\", summary[0])\n",
    "# print(get_file(\"my indian driving license\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7205a7f6-64c4-4b32-b0fd-7af24ac5747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_function_pattern(response: str) -> tuple[bool, list[bool] | None]:\n",
    "    \"\"\"\n",
    "    Check if the [boolean], [boolean], [boolean] pattern exists anywhere in the response\n",
    "    and extract the boolean values if found.\n",
    "    \n",
    "    Args:\n",
    "        response (str): The LLM's complete response string\n",
    "    \n",
    "    Returns:\n",
    "        tuple[bool, list[bool] | None]: \n",
    "            - First element: True if pattern was found, False otherwise\n",
    "            - Second element: List of 3 booleans if pattern was found, None otherwise\n",
    "    \n",
    "    Examples:\n",
    "        >>> extract_function_pattern(\"To do this task, I need: [true], [false], [false]\")\n",
    "        (True, [True, False, False])\n",
    "        >>> extract_function_pattern(\"Here's some regular text without pattern\")\n",
    "        (False, None)\n",
    "    \"\"\"\n",
    "    # Pattern to match [boolean], [boolean], [boolean]\n",
    "    pattern = r'\\[(true|false)\\],\\s*\\[(true|false)\\],\\s*\\[(true|false)\\]'\n",
    "    \n",
    "    # Search for pattern anywhere in the text\n",
    "    match = re.search(pattern, response.lower())\n",
    "    \n",
    "    if match:\n",
    "        # Extract the boolean values\n",
    "        bool_values = [val == 'true' for val in match.groups()]\n",
    "        return True, bool_values\n",
    "    \n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77b04c2-650b-44fb-a987-faf84028e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "class DocumentSearchSystem:\n",
    "    def __init__(self, index_file: str = \"faiss_index.bin\", metadata_file: str = \"metadata.json\"):\n",
    "        # Initialize the Sentence-BERT model for embedding generation\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # File paths for persistence\n",
    "        self.index_file = index_file\n",
    "        self.metadata_file = metadata_file\n",
    "\n",
    "        # List to store document metadata\n",
    "        self.documents = []\n",
    "\n",
    "        # Load or initialize FAISS index\n",
    "        self.dimension = 384  # Embedding size of 'all-MiniLM-L6-v2'\n",
    "        self.index = self._load_or_initialize_index()\n",
    "        \n",
    "        # Load document metadata\n",
    "        self._load_metadata()\n",
    "        \n",
    "    def _load_or_initialize_index(self):\n",
    "        \"\"\"Load the FAISS index from disk or initialize a new one if not found.\"\"\"\n",
    "        if os.path.exists(self.index_file):\n",
    "            index = faiss.read_index(self.index_file)\n",
    "            print(\"FAISS index loaded from disk.\")\n",
    "        else:\n",
    "            index = faiss.IndexFlatL2(self.dimension)  # L2 (Euclidean) index\n",
    "            print(\"New FAISS index created.\")\n",
    "        return index\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load document metadata from JSON file if it exists.\"\"\"\n",
    "        if os.path.exists(self.metadata_file):\n",
    "            with open(self.metadata_file, \"r\") as f:\n",
    "                self.documents = json.load(f)\n",
    "            print(\"Document metadata loaded from disk.\")\n",
    "        else:\n",
    "            self.documents = []\n",
    "    \n",
    "    def _save_index_and_metadata(self):\n",
    "        \"\"\"Save the FAISS index and document metadata to disk.\"\"\"\n",
    "        # Save the FAISS index\n",
    "        faiss.write_index(self.index, self.index_file)\n",
    "        \n",
    "        # Save the metadata as JSON\n",
    "        with open(self.metadata_file, \"w\") as f:\n",
    "            json.dump(self.documents, f)\n",
    "        \n",
    "        print(\"FAISS index and document metadata saved to disk.\")\n",
    "\n",
    "    def add_document(self, id: str, file_name: str, file_path: str, summary: str):\n",
    "        \"\"\"Add a document to the FAISS index and store its metadata.\"\"\"\n",
    "        # Generate the embedding for the summary\n",
    "        embedding = self.model.encode(summary).astype(np.float32).reshape(1, -1)\n",
    "        \n",
    "        # Add embedding to FAISS index\n",
    "        self.index.add(embedding)\n",
    "        \n",
    "        # Store metadata in documents list\n",
    "        self.documents.append({\n",
    "            \"id\": id,\n",
    "            \"file_name\": file_name,\n",
    "            \"file_path\": file_path,\n",
    "            \"summary\": summary\n",
    "        })\n",
    "        \n",
    "        print(f\"Added document: {file_name}\")\n",
    "        \n",
    "        # Save index and metadata\n",
    "        self._save_index_and_metadata()\n",
    "\n",
    "    def search_documents(self, doc_id: str, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Search for documents matching the query and return top_k results.\"\"\"\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = self.model.encode(query).astype(np.float32).reshape(1, -1)\n",
    "        \n",
    "        # Get indices of documents with matching doc_id\n",
    "        matching_indices = [i for i, doc in enumerate(self.documents) \n",
    "                        if doc.get('id') == doc_id]\n",
    "        \n",
    "        if not matching_indices:\n",
    "            return []  # Return empty list if no documents match the ID\n",
    "        \n",
    "        # Create a subset index with only the matching documents\n",
    "        subset_index = faiss.IndexFlatL2(self.dimension)\n",
    "        subset_embeddings = np.vstack([\n",
    "            self.index.reconstruct(i) for i in matching_indices\n",
    "        ])\n",
    "        subset_index.add(subset_embeddings)\n",
    "        \n",
    "        # Perform search in subset index\n",
    "        distances, indices = subset_index.search(query_embedding, min(top_k, len(matching_indices)))\n",
    "        \n",
    "        # Retrieve and return matching documents\n",
    "        results = []\n",
    "        for idx, distance in zip(indices[0], distances[0]):\n",
    "            if idx != -1:  # Ensure valid index\n",
    "                # doc = self.documents[idx]\n",
    "                # doc['score'] = 1 / (1 + distance)  # Convert distance to similarity score\n",
    "                # results.append(doc)\n",
    "\n",
    "                original_idx = matching_indices[idx]\n",
    "                doc = self.documents[original_idx].copy()  # Copy the metadata\n",
    "                doc['score'] = float(1 / (1 + distance))  # Convert to Python float\n",
    "                results.append(doc)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# # Usage example\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Initialize the document search system\n",
    "#     search_system = DocumentSearchSystem()\n",
    "    \n",
    "#     # Add some example documents\n",
    "#     search_system.add_document(\"doc1.txt\", \"/path/to/doc1.txt\", \"This is a summary about machine learning.\")\n",
    "#     search_system.add_document(\"doc2.txt\", \"/path/to/doc2.txt\", \"An introduction to artificial intelligence.\")\n",
    "#     search_system.add_document(\"doc3.txt\", \"/path/to/doc3.txt\", \"A document detailing natural language processing.\")\n",
    "    \n",
    "#     # Perform a search\n",
    "#     query = \"information about AI\"\n",
    "#     results = search_system.search_documents(query, top_k=2)\n",
    "    \n",
    "#     # Display results\n",
    "#     for result in results:\n",
    "#         print(f\"File Name: {result['file_name']}\")\n",
    "#         print(f\"File Path: {result['file_path']}\")\n",
    "#         print(f\"Summary: {result['summary']}\")\n",
    "#         print(f\"Score: {result['score']}\")\n",
    "#         print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f869900f-a0a6-45cd-896f-602f3e109df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded from disk.\n",
      "Document metadata loaded from disk.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.2.14:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [12/Jan/2025 17:46:20] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [12/Jan/2025 17:46:21] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [12/Jan/2025 17:46:23] \"GET / HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'image', 'image': <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1270x2000 at 0x1C6FD507340>, 'resized_height': 280, 'resized_width': 420}, {'type': 'text', 'text': 'You are a document summarization assistant. Your task is to create a comprehensive, searchable summary of a file based on its contents and provided description. Follow this structured approach:\\nGUIDELINES:\\n\\nFocus on discoverability - include terms users might search for\\nIncorporate both technical and layman\\'s terms\\nConsider different ways users might try to find this document\\nInclude crucial context from both the file content and user description\\nAdd industry-standard terminology where relevant\\nConsider various use cases and access patterns\\nMaintain factual accuracy while optimizing for searchability\\n\\nNow, analyze the provided file and description to generate a comprehensive summary like this, Do not exceed the numbers mentioned:\\n\\nINPUTS:\\nFile: attached pages as images. treat them combined as single file\\nUser Description: driving license\\nGenerate a summary in the following format:\\nCORE SUMMARY (2-3 sentences):\\n[Provide a clear, concise overview of the main content and purpose of the file]\\n\\nDOCUMENT TYPE & PURPOSE:\\n- Primary Purpose: [Main function/goal of the document]\\n- Document Category: [Report/Specification/Manual/Analysis/etc.]\\n- Target Audience: [Intended readers/users]\\n\\nKEY TOPICS:\\n- [Topic 1]\\n- [Topic 2]\\n- [Topic 3]\\n[List 3-5 main topics covered]\\n\\nREFERENCE CONTEXTS:\\n\"This file would be relevant when looking for...\"\\n- [Scenario 1]\\n- [Scenario 2]\\n- [Scenario 3]\\n[List 3-4 specific use cases or scenarios]\\n\\nADDITIONAL CONTEXT FROM USER DESCRIPTION:\\n[Integrate any unique insights or context from the user\\'s description that aren\\'t apparent from the file content alone]\\n\\nSEARCH KEYWORDS:\\n[List 8-12 relevant search terms, including:\\n- Common synonyms\\n- Technical terms\\n- Related concepts\\n- Alternative phrasings\\nSeparate with commas]\\n\\n'}]\n",
      "Saving summary: CORE SUMMARY (2-3 sentences):\n",
      "The file is a driving license issued to Dinesh Bansal. The document includes personal information such as name, date of birth, and address. It also contains a photograph of the individual and a QR code for verification purposes.\n",
      "\n",
      "DOCUMENT TYPE & PURPOSE:\n",
      "- Primary Purpose: Verification of identity and authorization to drive\n",
      "- Document Category: Official document\n",
      "- Target Audience: Drivers and authorized personnel\n",
      "\n",
      "KEY TOPICS:\n",
      "- Personal information\n",
      "- Photograph\n",
      "- QR code verification\n",
      "- Issuance date and validity period\n",
      "\n",
      "REFERENCE CONTEXTS:\n",
      "This file would be relevant when looking for verification of identity and authorization to drive.\n",
      "\n",
      "ADDITIONAL CONTEXT FROM USER DESCRIPTION:\n",
      "The document is issued by the Delhi Police, indicating its official nature. The photograph and QR code are used for verification purposes, ensuring the authenticity of the individual.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Jan/2025 17:48:46] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added document: Indian License.pdf\n",
      "FAISS index and document metadata saved to disk.\n",
      "Saved: C:/Users/Dishu/Desktop/Indian License.pdf,C\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "# Define upload folder\n",
    "UPLOAD_FOLDER = '/content/uploads'\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "search_system = DocumentSearchSystem()\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file_and_text():\n",
    "    # Get the text data from the request\n",
    "    text = request.form['text']\n",
    "    id = request.form['id']\n",
    "#    jarvis = JARVIS()\n",
    "#     online_jarvis = OnlineAgent(jarvis)\n",
    "#     content = [\n",
    "#         {\n",
    "#             \"role\":\"system\",\n",
    "#             \"content\":[\n",
    "#                 {\n",
    "#                     \"type\":\"text\",\n",
    "#                     \"text\":\"\"\"You are Jarvis, Dishu's AI assistant. For each user query, your ONLY task is to determine if any of these functions are needed to properly respond:\n",
    "\n",
    "# Available functions:\n",
    "# 1. save_file: Saves data to a file\n",
    "# 2. get_file: Reads data from a file  \n",
    "# 3. use_internet: Accesses internet resources\n",
    "\n",
    "# Response rules:\n",
    "# 1. IF ANY function is needed:\n",
    "#    - Respond ONLY with three boolean values, where AT LEAST ONE MUST BE TRUE: [save_file_needed], [get_file_needed], [use_internet_needed]\n",
    "#    - Do not add any other text\n",
    "#    Example responses:\n",
    "#    - For saving content: [true], [false], [false]\n",
    "#    - For reading saved content: [false], [true], [false] \n",
    "#    - For checking weather: [false], [false], [true]\n",
    "#    - For tasks needing multiple functions: [true], [true], [false]\n",
    "\n",
    "# 2. IF NO functions are needed:\n",
    "#    - DO NOT use the boolean format\n",
    "#    - Respond conversationally with the direct answer\n",
    "#    - Example: \"2+2 equals 4\"\n",
    "\n",
    "# Never output [false], [false], [false] - if no functions are needed, give a direct answer instead.\"\"\"\n",
    "#                 }\n",
    "#             ]\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\":\"user\",\n",
    "#             \"content\":[\n",
    "#                 {\n",
    "#                     \"type\":\"text\",\n",
    "#                     \"text\":text\n",
    "#                 }\n",
    "#             ]\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     output = jarvis.ask(content)\n",
    "\n",
    "#     has_pattern, bool_values = extract_function_pattern(output[0])\n",
    "\n",
    "#     if has_pattern:\n",
    "#         save_file, retrieve_file, use_internet = bool_values\n",
    "#         if save_file or retrieve_file:\n",
    "            # Check if a file is part of the request\n",
    "    if 'file' not in request.files:\n",
    "        # scores = get_file(text)\n",
    "        # print(scores)\n",
    "        results = search_system.search_documents(doc_id=id, query=text)\n",
    "        output = {}\n",
    "        i = 1\n",
    "        for r in results:\n",
    "            output[str(i)] = [r['file_name'], r['file_path'], str(r['score'])]\n",
    "            i += 1\n",
    "        return jsonify({\"text\": output, \"got_file\": \"true\"}) \n",
    "    else:\n",
    "        file = request.files['file']\n",
    "        path = request.form['path']\n",
    "        # Save the file securely\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "        file.save(file_path)\n",
    "    \n",
    "        summary = generate_summary(file_path, text)\n",
    "        print(\"Saving summary: \" + summary)\n",
    "        #db.save_summary(file.filename, path, summary)\n",
    "        search_system.add_document(\n",
    "                id=id,\n",
    "                file_name=file.filename,\n",
    "                file_path=path,\n",
    "                summary=summary\n",
    "            )\n",
    "        print(\"Saved: \" + path + \",\" + summary[0])\n",
    "    \n",
    "        # Return a response with the text and file path (for example purposes)\n",
    "        output = {\"text\": \"Saved: \" + path, \"file_saved\": file_path}\n",
    "        return jsonify(output)\n",
    "        # if use_internet:\n",
    "        #     output = online_jarvis.search(text)\n",
    "        #     print(\"Internet: \"+ output)\n",
    "        #     return jsonify({\"text\": output})\n",
    "    # print(output[0])\n",
    "    # return jsonify({\"text\": output[0]})\n",
    "            \n",
    "\n",
    "@app.route('/download', methods=['GET'])\n",
    "def download_file():\n",
    "    # Get the filename from the query parameters\n",
    "    filename = request.args.get('filename')\n",
    "    \n",
    "    # Construct the full path\n",
    "    file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        abort(404)  # Return 404 if the file is not found\n",
    "\n",
    "    # Send the file as an attachment\n",
    "    return send_file(file_path, as_attachment=True)\n",
    "\n",
    "app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f2ebb-6599-44a0-9085-ede6acbc8a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
