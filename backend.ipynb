{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f18883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: flask-sqlalchemy in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: flask-session in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (0.8.0)\n",
      "Collecting flask-login\n",
      "  Downloading Flask_Login-0.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.9 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.16 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from flask-sqlalchemy) (2.0.36)\n",
      "Requirement already satisfied: msgspec>=0.18.6 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from flask-session) (0.18.6)\n",
      "Requirement already satisfied: cachelib in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from flask-session) (0.13.0)\n",
      "Requirement already satisfied: colorama in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from sqlalchemy>=2.0.16->flask-sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\ai\\pytorch practice\\.conda\\lib\\site-packages (from sqlalchemy>=2.0.16->flask-sqlalchemy) (3.1.1)\n",
      "Downloading Flask_Login-0.6.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: flask-login\n",
      "Successfully installed flask-login-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install flask flask-sqlalchemy flask-session flask-login\n",
    "!pip install qwen-vl-utils transformers accelerate pdf2image llm-axe\n",
    "!pip install faiss-cpu sentence-transformers numpy\n",
    "!pip install --ignore-installed flask\n",
    "!apt update\n",
    "!apt install poppler-utils -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, redirect, url_for, render_template, flash, session\n",
    "# from flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\n",
    "# from flask_sqlalchemy import SQLAlchemy\n",
    "# from flask_session import Session\n",
    "# import os\n",
    "\n",
    "# app = Flask(__name__)\n",
    "# app.secret_key = 'dishuKB@852'\n",
    "\n",
    "# # Configure database\n",
    "# app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///users.db'\n",
    "# app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "\n",
    "# # Configure server-side sessions\n",
    "# app.config['SESSION_TYPE'] = 'filesystem'\n",
    "# Session(app)\n",
    "\n",
    "# # Initialize database and Flask-Login\n",
    "# db = SQLAlchemy(app)\n",
    "# login_manager = LoginManager()\n",
    "# login_manager.init_app(app)\n",
    "# login_manager.login_view = 'login'\n",
    "\n",
    "# # User model for database\n",
    "# class User(db.Model, UserMixin):\n",
    "#     id = db.Column(db.Integer, primary_key=True)\n",
    "#     username = db.Column(db.String(150), unique=True, nullable=False)\n",
    "#     password = db.Column(db.String(150), nullable=False)\n",
    "#     session_token = db.Column(db.String(150), nullable=True)\n",
    "\n",
    "# # Create the database tables if they don't exist\n",
    "# with app.app_context():\n",
    "#     db.create_all()\n",
    "\n",
    "# # Flask-Login user loader\n",
    "# @login_manager.user_loader\n",
    "# def load_user(user_id):\n",
    "#     return User.query.get(int(user_id))\n",
    "\n",
    "# # Routes\n",
    "# @app.route('/login', methods=['GET', 'POST'])\n",
    "# def login():\n",
    "#     if request.method == 'POST':\n",
    "#         username = request.form['username']\n",
    "#         password = request.form['password']\n",
    "#         user = User.query.filter_by(username=username).first()\n",
    "\n",
    "#         if user and user.password == password:\n",
    "#             login_user(user)\n",
    "#             session['session_token'] = os.urandom(24).hex()  # Generate a session token\n",
    "#             user.session_token = session['session_token']\n",
    "#             db.session.commit()\n",
    "#             flash('Logged in successfully.')\n",
    "#             return redirect(url_for('protected'))\n",
    "#         else:\n",
    "#             flash('Invalid username or password.')\n",
    "#     return render_template('login.html')\n",
    "\n",
    "# @app.route('/protected')\n",
    "# @login_required\n",
    "# def protected():\n",
    "#     return f'Hello, {current_user.username}! You are logged in.'\n",
    "\n",
    "# @app.route('/logout')\n",
    "# @login_required\n",
    "# def logout():\n",
    "#     current_user.session_token = None\n",
    "#     db.session.commit()\n",
    "#     logout_user()\n",
    "#     session.pop('session_token', None)\n",
    "#     flash('Logged out successfully.')\n",
    "#     return redirect(url_for('login'))\n",
    "\n",
    "# @app.before_request\n",
    "# def check_session():\n",
    "#     # Check if the user is authenticated via session token\n",
    "#     if 'session_token' in session:\n",
    "#         user = User.query.filter_by(session_token=session['session_token']).first()\n",
    "#         if user:\n",
    "#             login_user(user)\n",
    "\n",
    "# @app.route('/register', methods=['GET', 'POST'])\n",
    "# def register():\n",
    "#     if request.method == 'POST':\n",
    "#         username = request.form['username']\n",
    "#         password = request.form['password']\n",
    "#         if User.query.filter_by(username=username).first():\n",
    "#             flash('Username already exists.')\n",
    "#         else:\n",
    "#             new_user = User(username=username, password=password)\n",
    "#             db.session.add(new_user)\n",
    "#             db.session.commit()\n",
    "#             flash('User registered successfully.')\n",
    "#             return redirect(url_for('login'))\n",
    "#     return render_template('register.html')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139a497d-f336-471a-bffb-16a14d77f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from accelerate import Accelerator\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from llm_axe.agents import OnlineAgent\n",
    "from pathlib import Path\n",
    "import os\n",
    "from flask import Flask, request, jsonify, send_file, abort\n",
    "from werkzeug.utils import secure_filename\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39ee8cb-717b-4fd2-853d-5e5fe3565a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2289d5fe-852f-4715-b10a-363696b750e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983e8b63af7743c8b084c048244a9a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default: Load the model on the available device(s)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n",
    "\n",
    "# The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed740a8b-e87f-4e69-81da-07460bdef987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLiteFileSummaryStorage:\n",
    "    \"\"\"Store file summaries using SQLite\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path=\"file_summaries.db\"):\n",
    "        self.db_path = db_path\n",
    "        self._ensure_database_exists()\n",
    "    \n",
    "    def _ensure_database_exists(self):\n",
    "        \"\"\"Create database and table if they don't exist\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS file_summaries (\n",
    "                filename TEXT PRIMARY KEY,\n",
    "                filepath TEXT,\n",
    "                summary TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def save_summary(self, filename, filepath, summary):\n",
    "        \"\"\"Save a file summary\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                INSERT OR REPLACE INTO file_summaries (filename, filepath, summary)\n",
    "                VALUES (?, ?, ?)\n",
    "            ''', (filename, filepath, summary))\n",
    "            \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving summary: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_summary(self, filename):\n",
    "        \"\"\"Retrieve a file summary\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                SELECT summary FROM file_summaries\n",
    "                WHERE filename = ?\n",
    "            ''', (filename,))\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "            conn.close()\n",
    "            \n",
    "            return result[0] if result else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving summary: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_all_summaries(self):\n",
    "        \"\"\"Get all stored summaries\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                SELECT filename, filepath, summary, timestamp \n",
    "                FROM file_summaries\n",
    "            ''')\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            conn.close()\n",
    "            \n",
    "            return {row[0]: {\n",
    "                'filepath': row[1],\n",
    "                'summary': row[2],\n",
    "                'timestamp': row[3]\n",
    "            } for row in results}\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving summaries: {e}\")\n",
    "            return {}\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# def main():\n",
    "#     # Example using JSON storage\n",
    "#     json_storage = JSONFileSummaryStorage()\n",
    "    \n",
    "#     # Save some summaries\n",
    "#     json_storage.save_summary(\"document1.pdf\", \"This is a report about quarterly earnings\")\n",
    "#     json_storage.save_summary(\"image1.jpg\", \"A landscape photo of mountains\")\n",
    "    \n",
    "#     # Retrieve a specific summary\n",
    "#     print(json_storage.get_summary(\"document1.pdf\"))\n",
    "    \n",
    "#     # Get all summaries\n",
    "#     print(json_storage.get_all_summaries())\n",
    "    \n",
    "#     # Example using SQLite storage\n",
    "#     sqlite_storage = SQLiteFileSummaryStorage()\n",
    "    \n",
    "#     # Save some summaries\n",
    "#     sqlite_storage.save_summary(\"document1.pdf\", \"This is a report about quarterly earnings\")\n",
    "#     sqlite_storage.save_summary(\"image1.jpg\", \"A landscape photo of mountains\")\n",
    "    \n",
    "#     # Retrieve a specific summary\n",
    "#     print(sqlite_storage.get_summary(\"document1.pdf\"))\n",
    "    \n",
    "#     # Get all summaries\n",
    "#     print(sqlite_storage.get_all_summaries())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44689e5-be1a-469a-b13f-a1ac51481809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path, output_folder):\n",
    "    \n",
    "    for i, page in enumerate(images):\n",
    "        page.save(f\"{output_folder}/page_{i + 1}.png\", \"PNG\")\n",
    "\n",
    "# # Example usage\n",
    "# pdf_to_images(\"example.pdf\", \"output_images_folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ababfcd4-05a5-4533-8719-6b796f9ba227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_format(messages: list[dict]) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if the messages are already in the correct format.\n",
    "    \n",
    "    Correct format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"message text\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Args:\n",
    "        messages (list[dict]): List of message dictionaries to validate\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if format is correct, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(messages, list):\n",
    "            return False\n",
    "            \n",
    "        for message in messages:\n",
    "            # Check if basic structure exists\n",
    "            if not isinstance(message, dict):\n",
    "                return False\n",
    "                \n",
    "            if 'role' not in message or 'content' not in message:\n",
    "                return False\n",
    "                \n",
    "            # Check role\n",
    "            if not isinstance(message['role'], str):\n",
    "                return False\n",
    "                \n",
    "            # Check content structure\n",
    "            content = message['content']\n",
    "            if not isinstance(content, list):\n",
    "                return False\n",
    "                \n",
    "            # Validate each content item\n",
    "            for item in content:\n",
    "                if not isinstance(item, dict):\n",
    "                    return False\n",
    "                    \n",
    "                if 'type' not in item or 'text' not in item:\n",
    "                    return False\n",
    "                    \n",
    "                if item['type'] != 'text':\n",
    "                    return False\n",
    "                    \n",
    "                if not isinstance(item['text'], str):\n",
    "                    return False\n",
    "                    \n",
    "        return True\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def convert_message_format(messages: list[dict]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Converts messages from simple format to the structured format required by the model.\n",
    "    \n",
    "    Input format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"message text\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Output format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"message text\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Args:\n",
    "        messages (list[dict]): List of message dictionaries in simple format\n",
    "        \n",
    "    Returns:\n",
    "        list[dict]: List of message dictionaries in structured format\n",
    "    \"\"\"\n",
    "    converted_messages = []\n",
    "    \n",
    "    for message in messages:\n",
    "        # Handle case where content is already in the correct format\n",
    "        if isinstance(message.get('content'), list):\n",
    "            converted_messages.append(message)\n",
    "            continue\n",
    "            \n",
    "        # Convert simple string content to structured format\n",
    "        converted_message = {\n",
    "            \"role\": message[\"role\"],\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": message[\"content\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        converted_messages.append(converted_message)\n",
    "    \n",
    "    return converted_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84bdf40f-197b-4c47-ba01-f38073469623",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JARVIS():\n",
    "\n",
    "    # Your ask function will always receive a list of prompts\n",
    "    # The prompts are in open ai prompt format\n",
    "    #  example: {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "    # If your model supports json format, use the format parameter to specify that to your model.\n",
    "    def ask(self, messages:list, format:str=\"\", temperature:float=0.8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prompts (list): A list of prompts to ask.\n",
    "            format (str, optional): The format of the response. Use \"json\" for json. Defaults to \"\".\n",
    "            temperature (float, optional): The temperature of the LLM. Defaults to 0.8.\n",
    "        \"\"\"\n",
    "        correct_format = is_correct_format(messages)\n",
    "        if not correct_format:\n",
    "            messages = convert_message_format(messages)\n",
    "        # Preparation for inference\n",
    "        text = processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        \n",
    "        # Inference: Generation of the output\n",
    "        generated_ids = model.generate(**inputs, max_new_tokens=1024)\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        if not correct_format:\n",
    "            return output_text[0]\n",
    "        return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea95c0f9-ae67-4a44-93f5-b90350fcfbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "jarvis = JARVIS()\n",
    "online_jarvis = OnlineAgent(jarvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1f575433-fe1f-48be-9453-70853e80021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': [{'type': 'text', 'text': 'Instructions:\\nYou are a smart online searcher for a large language model.\\nGiven information, you must create a search query to search the internet for relevant information.\\n\\nYour search query must be in the form of a json response.\\n\\nExact json response format must be as follows:\\n\\n{\\n    \"search_query\": \"your search query\"\\n}\\n- Your must only provide ONE search query\\n- You must provide the BEST search query for the given information\\n- The search query must be normal text.\\n'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': 'What is the weather in Toronto today?'}]}]\n",
      "After: \n",
      "[{'role': 'system', 'content': [{'type': 'text', 'text': 'Instructions:\\nYou are a smart online searcher for a large language model.\\nGiven information, you must create a search query to search the internet for relevant information.\\n\\nYour search query must be in the form of a json response.\\n\\nExact json response format must be as follows:\\n\\n{\\n    \"search_query\": \"your search query\"\\n}\\n- Your must only provide ONE search query\\n- You must provide the BEST search query for the given information\\n- The search query must be normal text.\\n'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': 'What is the weather in Toronto today?'}]}]\n",
      "['{\\n    \"search_query\": \"weather in Toronto today\"\\n}']\n"
     ]
    }
   ],
   "source": [
    "c2 = [{'role': 'system', 'content': [{'type': 'text', 'text': 'Instructions:\\nYou are a smart online searcher for a large language model.\\nGiven information, you must create a search query to search the internet for relevant information.\\n\\nYour search query must be in the form of a json response.\\n\\nExact json response format must be as follows:\\n\\n{\\n    \"search_query\": \"your search query\"\\n}\\n- Your must only provide ONE search query\\n- You must provide the BEST search query for the given information\\n- The search query must be normal text.\\n'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': 'What is the weather in Toronto today?'}]}]\n",
    "print(jarvis.ask(c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c4887418-f0cb-4ed6-a0e9-c954abcac1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on information from the internet, the weather in Toronto today is 52°C with mostly cloudy conditions.\n"
     ]
    }
   ],
   "source": [
    "content = \"What is the weather in Toronto today? reply with today's date and temperature in celsius\"\n",
    "print(online_jarvis.search(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6adc0991-c74e-4dce-93e8-08e3cb614d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "db = SQLiteFileSummaryStorage()\n",
    "def generate_summary(filepath, query):\n",
    "    jarvis = JARVIS()\n",
    "    content = []\n",
    "    if filepath.endswith(\".jpg\") or filepath.endswith(\".jpeg\"):\n",
    "        content.append({\n",
    "            \"type\":\"image\",\n",
    "            \"image\":filepath,\n",
    "            \"resized_height\": 280,\n",
    "            \"resized_width\": 420,\n",
    "        })\n",
    "    else:\n",
    "        images = convert_from_path(filepath)\n",
    "        for i, page in enumerate(images):\n",
    "            content.append({\n",
    "                \"type\":\"image\",\n",
    "                \"image\":page,\n",
    "                \"resized_height\": 280,\n",
    "                \"resized_width\": 420,\n",
    "            })\n",
    "    content.append({\"type\": \"text\", \"text\": f\"\"\"You are a document summarization assistant. Your task is to create a comprehensive, searchable summary of a file based on its contents and provided description. Follow this structured approach:\n",
    "GUIDELINES:\n",
    "\n",
    "Focus on discoverability - include terms users might search for\n",
    "Incorporate both technical and layman's terms\n",
    "Consider different ways users might try to find this document\n",
    "Include crucial context from both the file content and user description\n",
    "Add industry-standard terminology where relevant\n",
    "Consider various use cases and access patterns\n",
    "Maintain factual accuracy while optimizing for searchability\n",
    "\n",
    "Now, analyze the provided file and description to generate a comprehensive summary like this, Do not exceed the numbers mentioned:\n",
    "\n",
    "INPUTS:\n",
    "File: attached pages as images. treat them combined as single file\n",
    "User Description: {query}\n",
    "Generate a summary in the following format:\n",
    "CORE SUMMARY (2-3 sentences):\n",
    "[Provide a clear, concise overview of the main content and purpose of the file]\n",
    "\n",
    "DOCUMENT TYPE & PURPOSE:\n",
    "- Primary Purpose: [Main function/goal of the document]\n",
    "- Document Category: [Report/Specification/Manual/Analysis/etc.]\n",
    "- Target Audience: [Intended readers/users]\n",
    "\n",
    "KEY TOPICS:\n",
    "- [Topic 1]\n",
    "- [Topic 2]\n",
    "- [Topic 3]\n",
    "[List 3-5 main topics covered]\n",
    "\n",
    "REFERENCE CONTEXTS:\n",
    "\"This file would be relevant when looking for...\"\n",
    "- [Scenario 1]\n",
    "- [Scenario 2]\n",
    "- [Scenario 3]\n",
    "[List 3-4 specific use cases or scenarios]\n",
    "\n",
    "ADDITIONAL CONTEXT FROM USER DESCRIPTION:\n",
    "[Integrate any unique insights or context from the user's description that aren't apparent from the file content alone]\n",
    "\n",
    "SEARCH KEYWORDS:\n",
    "[List 8-12 relevant search terms, including:\n",
    "- Common synonyms\n",
    "- Technical terms\n",
    "- Related concepts\n",
    "- Alternative phrasings\n",
    "Separate with commas]\n",
    "\n",
    "\"\"\"})\n",
    "    print(content)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content,\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    output_text = jarvis.ask(messages)\n",
    "    return output_text\n",
    "\n",
    "def get_file(query):\n",
    "    jarvis = JARVIS()\n",
    "    summaries = db.get_all_summaries()\n",
    "    print(len(summaries.items()))\n",
    "    print(query)\n",
    "    scores = \"\"\n",
    "    for filename, data in summaries.items():\n",
    "        summary = data['summary']\n",
    "        path = data['filepath']\n",
    "        print(\"Summary: \" + summary)\n",
    "        print(\"Query: \" + query)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"\"\"You are a document matching expert. Analyze how well a query matches a given summary and provide a single confidence score from 0-100.\n",
    "\n",
    "Scoring Criteria:\n",
    "1. Exact Keyword Matches (40 points max):\n",
    "   - Exact matches of query terms (case-insensitive)\n",
    "   - Multiple occurrences increase score\n",
    "   - Technical/specific terms worth more than common words\n",
    "   - Title/key position matches worth more\n",
    "\n",
    "2. Keyword Variations (30 points max):\n",
    "   - Plurals/singulars (car/cars)\n",
    "   - Common synonyms (vehicle/automobile)\n",
    "   - Word forms (run/running/ran)\n",
    "   - Compound variations (healthcare/health care)\n",
    "\n",
    "3. Semantic Relevance (20 points max):\n",
    "   - Topic and concept alignment\n",
    "   - Context relevance\n",
    "\n",
    "4. Additional Factors (10 points max):\n",
    "   - Term proximity\n",
    "   - Information relevance\n",
    "\n",
    "Query: {query}\n",
    "Summary: {summary}\n",
    "\n",
    "Follow these steps silently:\n",
    "1. Check exact keyword matches\n",
    "2. Find keyword variations\n",
    "3. Assess semantic alignment\n",
    "4. Consider additional factors\n",
    "5. Sum up scores\n",
    "\n",
    "Output only this format:\n",
    "Confidence Score: <0-100>\"\"\"},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        output_text = jarvis.ask(messages)\n",
    "        scores += f\"({filename},{path},{str(output_text[0])})\\n\"\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3851ad07-7d80-453e-8d53-7db6b6a3699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'image', 'image': <PIL.PpmImagePlugin.PpmImageFile image mode=RGB size=1270x2000 at 0x7F9D40642550>, 'resized_height': 280, 'resized_width': 420}, {'type': 'text', 'text': 'You are a document summarization assistant. Your task is to create a comprehensive, searchable summary of a file based on its contents and provided description. Follow this structured approach:\\nGUIDELINES:\\n\\nFocus on discoverability - include terms users might search for\\nIncorporate both technical and layman\\'s terms\\nConsider different ways users might try to find this document\\nInclude crucial context from both the file content and user description\\nAdd industry-standard terminology where relevant\\nConsider various use cases and access patterns\\nMaintain factual accuracy while optimizing for searchability\\n\\nNow, analyze the provided file and description to generate a comprehensive summary like this, Do not exceed the numbers mentioned:\\n\\nINPUTS:\\nFile: attached pages as images. treat them combined as single file\\nUser Description: My indian driving license\\nGenerate a summary in the following format:\\nCORE SUMMARY (2-3 sentences):\\n[Provide a clear, concise overview of the main content and purpose of the file]\\n\\nDOCUMENT TYPE & PURPOSE:\\n- Primary Purpose: [Main function/goal of the document]\\n- Document Category: [Report/Specification/Manual/Analysis/etc.]\\n- Target Audience: [Intended readers/users]\\n\\nKEY TOPICS:\\n- [Topic 1]\\n- [Topic 2]\\n- [Topic 3]\\n[List 3-5 main topics covered]\\n\\nREFERENCE CONTEXTS:\\n\"This file would be relevant when looking for...\"\\n- [Scenario 1]\\n- [Scenario 2]\\n- [Scenario 3]\\n[List 3-4 specific use cases or scenarios]\\n\\nADDITIONAL CONTEXT FROM USER DESCRIPTION:\\n[Integrate any unique insights or context from the user\\'s description that aren\\'t apparent from the file content alone]\\n\\nSEARCH KEYWORDS:\\n[List 8-12 relevant search terms, including:\\n- Common synonyms\\n- Technical terms\\n- Related concepts\\n- Alternative phrasings\\nSeparate with commas]\\n\\n'}]\n",
      "1\n",
      "my indian driving license\n",
      "(Indian License.pdf,Indian License.pdf,Confidence Score: 90)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = generate_summary(\"Indian License.pdf\", \"My indian driving license\")\n",
    "db.save_summary(\"Indian License.pdf\", \"Indian License.pdf\", summary[0])\n",
    "print(get_file(\"my indian driving license\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7205a7f6-64c4-4b32-b0fd-7af24ac5747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_function_pattern(response: str) -> tuple[bool, list[bool] | None]:\n",
    "    \"\"\"\n",
    "    Check if the [boolean], [boolean], [boolean] pattern exists anywhere in the response\n",
    "    and extract the boolean values if found.\n",
    "    \n",
    "    Args:\n",
    "        response (str): The LLM's complete response string\n",
    "    \n",
    "    Returns:\n",
    "        tuple[bool, list[bool] | None]: \n",
    "            - First element: True if pattern was found, False otherwise\n",
    "            - Second element: List of 3 booleans if pattern was found, None otherwise\n",
    "    \n",
    "    Examples:\n",
    "        >>> extract_function_pattern(\"To do this task, I need: [true], [false], [false]\")\n",
    "        (True, [True, False, False])\n",
    "        >>> extract_function_pattern(\"Here's some regular text without pattern\")\n",
    "        (False, None)\n",
    "    \"\"\"\n",
    "    # Pattern to match [boolean], [boolean], [boolean]\n",
    "    pattern = r'\\[(true|false)\\],\\s*\\[(true|false)\\],\\s*\\[(true|false)\\]'\n",
    "    \n",
    "    # Search for pattern anywhere in the text\n",
    "    match = re.search(pattern, response.lower())\n",
    "    \n",
    "    if match:\n",
    "        # Extract the boolean values\n",
    "        bool_values = [val == 'true' for val in match.groups()]\n",
    "        return True, bool_values\n",
    "    \n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c77b04c2-650b-44fb-a987-faf84028e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "class DocumentSearchSystem:\n",
    "    def __init__(self, index_file: str = \"faiss_index.bin\", metadata_file: str = \"metadata.json\"):\n",
    "        # Initialize the Sentence-BERT model for embedding generation\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # File paths for persistence\n",
    "        self.index_file = index_file\n",
    "        self.metadata_file = metadata_file\n",
    "\n",
    "        # List to store document metadata\n",
    "        self.documents = []\n",
    "\n",
    "        # Load or initialize FAISS index\n",
    "        self.dimension = 384  # Embedding size of 'all-MiniLM-L6-v2'\n",
    "        self.index = self._load_or_initialize_index()\n",
    "        \n",
    "        # Load document metadata\n",
    "        self._load_metadata()\n",
    "        \n",
    "    def _load_or_initialize_index(self):\n",
    "        \"\"\"Load the FAISS index from disk or initialize a new one if not found.\"\"\"\n",
    "        if os.path.exists(self.index_file):\n",
    "            index = faiss.read_index(self.index_file)\n",
    "            print(\"FAISS index loaded from disk.\")\n",
    "        else:\n",
    "            index = faiss.IndexFlatL2(self.dimension)  # L2 (Euclidean) index\n",
    "            print(\"New FAISS index created.\")\n",
    "        return index\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        \"\"\"Load document metadata from JSON file if it exists.\"\"\"\n",
    "        if os.path.exists(self.metadata_file):\n",
    "            with open(self.metadata_file, \"r\") as f:\n",
    "                self.documents = json.load(f)\n",
    "            print(\"Document metadata loaded from disk.\")\n",
    "        else:\n",
    "            self.documents = []\n",
    "    \n",
    "    def _save_index_and_metadata(self):\n",
    "        \"\"\"Save the FAISS index and document metadata to disk.\"\"\"\n",
    "        # Save the FAISS index\n",
    "        faiss.write_index(self.index, self.index_file)\n",
    "        \n",
    "        # Save the metadata as JSON\n",
    "        with open(self.metadata_file, \"w\") as f:\n",
    "            json.dump(self.documents, f)\n",
    "        \n",
    "        print(\"FAISS index and document metadata saved to disk.\")\n",
    "\n",
    "    def add_document(self, file_name: str, file_path: str, summary: str):\n",
    "        \"\"\"Add a document to the FAISS index and store its metadata.\"\"\"\n",
    "        # Generate the embedding for the summary\n",
    "        embedding = self.model.encode(summary).astype(np.float32).reshape(1, -1)\n",
    "        \n",
    "        # Add embedding to FAISS index\n",
    "        self.index.add(embedding)\n",
    "        \n",
    "        # Store metadata in documents list\n",
    "        self.documents.append({\n",
    "            \"file_name\": file_name,\n",
    "            \"file_path\": file_path,\n",
    "            \"summary\": summary\n",
    "        })\n",
    "        \n",
    "        print(f\"Added document: {file_name}\")\n",
    "        \n",
    "        # Save index and metadata\n",
    "        self._save_index_and_metadata()\n",
    "\n",
    "    def search_documents(self, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Search for documents matching the query and return top_k results.\"\"\"\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = self.model.encode(query).astype(np.float32).reshape(1, -1)\n",
    "        \n",
    "        # Perform search in FAISS index\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Retrieve and return matching documents\n",
    "        results = []\n",
    "        for idx, distance in zip(indices[0], distances[0]):\n",
    "            if idx != -1:  # Ensure valid index\n",
    "                doc = self.documents[idx]\n",
    "                doc['score'] = 1 / (1 + distance)  # Convert distance to similarity score\n",
    "                results.append(doc)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# # Usage example\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Initialize the document search system\n",
    "#     search_system = DocumentSearchSystem()\n",
    "    \n",
    "#     # Add some example documents\n",
    "#     search_system.add_document(\"doc1.txt\", \"/path/to/doc1.txt\", \"This is a summary about machine learning.\")\n",
    "#     search_system.add_document(\"doc2.txt\", \"/path/to/doc2.txt\", \"An introduction to artificial intelligence.\")\n",
    "#     search_system.add_document(\"doc3.txt\", \"/path/to/doc3.txt\", \"A document detailing natural language processing.\")\n",
    "    \n",
    "#     # Perform a search\n",
    "#     query = \"information about AI\"\n",
    "#     results = search_system.search_documents(query, top_k=2)\n",
    "    \n",
    "#     # Display results\n",
    "#     for result in results:\n",
    "#         print(f\"File Name: {result['file_name']}\")\n",
    "#         print(f\"File Path: {result['file_path']}\")\n",
    "#         print(f\"Summary: {result['summary']}\")\n",
    "#         print(f\"Score: {result['score']}\")\n",
    "#         print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869900f-a0a6-45cd-896f-602f3e109df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded from disk.\n",
      "Document metadata loaded from disk.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:4998\n",
      " * Running on http://192.168.84.2:4998\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [22/Nov/2024 07:11:29] \"POST /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2024 07:11:51] \"POST /upload HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [22/Nov/2024 07:12:05] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "# Define upload folder\n",
    "UPLOAD_FOLDER = '/content/uploads'\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "search_system = DocumentSearchSystem()\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file_and_text():\n",
    "    # Get the text data from the request\n",
    "    text = request.form['text']\n",
    "#    jarvis = JARVIS()\n",
    "#     online_jarvis = OnlineAgent(jarvis)\n",
    "#     content = [\n",
    "#         {\n",
    "#             \"role\":\"system\",\n",
    "#             \"content\":[\n",
    "#                 {\n",
    "#                     \"type\":\"text\",\n",
    "#                     \"text\":\"\"\"You are Jarvis, Dishu's AI assistant. For each user query, your ONLY task is to determine if any of these functions are needed to properly respond:\n",
    "\n",
    "# Available functions:\n",
    "# 1. save_file: Saves data to a file\n",
    "# 2. get_file: Reads data from a file  \n",
    "# 3. use_internet: Accesses internet resources\n",
    "\n",
    "# Response rules:\n",
    "# 1. IF ANY function is needed:\n",
    "#    - Respond ONLY with three boolean values, where AT LEAST ONE MUST BE TRUE: [save_file_needed], [get_file_needed], [use_internet_needed]\n",
    "#    - Do not add any other text\n",
    "#    Example responses:\n",
    "#    - For saving content: [true], [false], [false]\n",
    "#    - For reading saved content: [false], [true], [false] \n",
    "#    - For checking weather: [false], [false], [true]\n",
    "#    - For tasks needing multiple functions: [true], [true], [false]\n",
    "\n",
    "# 2. IF NO functions are needed:\n",
    "#    - DO NOT use the boolean format\n",
    "#    - Respond conversationally with the direct answer\n",
    "#    - Example: \"2+2 equals 4\"\n",
    "\n",
    "# Never output [false], [false], [false] - if no functions are needed, give a direct answer instead.\"\"\"\n",
    "#                 }\n",
    "#             ]\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\":\"user\",\n",
    "#             \"content\":[\n",
    "#                 {\n",
    "#                     \"type\":\"text\",\n",
    "#                     \"text\":text\n",
    "#                 }\n",
    "#             ]\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     output = jarvis.ask(content)\n",
    "\n",
    "#     has_pattern, bool_values = extract_function_pattern(output[0])\n",
    "\n",
    "#     if has_pattern:\n",
    "#         save_file, retrieve_file, use_internet = bool_values\n",
    "#         if save_file or retrieve_file:\n",
    "            # Check if a file is part of the request\n",
    "    if 'file' not in request.files:\n",
    "        # scores = get_file(text)\n",
    "        # print(scores)\n",
    "        results = search_system.search_documents(text)\n",
    "        output = {}\n",
    "        i = 1\n",
    "        for r in results:\n",
    "            output[str(i)] = [r['file_name'], r['file_path'], r['score']]\n",
    "            i += 1\n",
    "        return jsonify({\"text\": output, \"got_file\": \"true\"}) \n",
    "    else:\n",
    "        file = request.files['file']\n",
    "        path = request.form['path']\n",
    "        # Save the file securely\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "        file.save(file_path)\n",
    "    \n",
    "        summary = generate_summary(file_path, text)\n",
    "        print(\"Saving summary: \" + summary)\n",
    "        #db.save_summary(file.filename, path, summary)\n",
    "        search_system.add_document(\n",
    "                file_name=file.filename,\n",
    "                file_path=path,\n",
    "                summary=summary\n",
    "            )\n",
    "        print(\"Saved: \" + path + \",\" + summary[0])\n",
    "    \n",
    "        # Return a response with the text and file path (for example purposes)\n",
    "        output = {\"text\": \"Saved: \" + path, \"file_saved\": file_path}\n",
    "        return jsonify(output)\n",
    "        # if use_internet:\n",
    "        #     output = online_jarvis.search(text)\n",
    "        #     print(\"Internet: \"+ output)\n",
    "        #     return jsonify({\"text\": output})\n",
    "    # print(output[0])\n",
    "    # return jsonify({\"text\": output[0]})\n",
    "            \n",
    "\n",
    "@app.route('/download', methods=['GET'])\n",
    "def download_file():\n",
    "    # Get the filename from the query parameters\n",
    "    filename = request.args.get('filename')\n",
    "    \n",
    "    # Construct the full path\n",
    "    file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        abort(404)  # Return 404 if the file is not found\n",
    "\n",
    "    # Send the file as an attachment\n",
    "    return send_file(file_path, as_attachment=True)\n",
    "\n",
    "app.run(host=\"0.0.0.0\", port=4998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f2ebb-6599-44a0-9085-ede6acbc8a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
