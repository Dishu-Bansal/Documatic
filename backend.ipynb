{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f18883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in d:\\special\\documatic\\.venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: flask-sqlalchemy in d:\\special\\documatic\\.venv\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: flask-session in d:\\special\\documatic\\.venv\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: flask-login in d:\\special\\documatic\\.venv\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: torchvision in d:\\special\\documatic\\.venv\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.16 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask-sqlalchemy) (2.0.37)\n",
      "Requirement already satisfied: msgspec>=0.18.6 in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask-session) (0.19.0)\n",
      "Requirement already satisfied: cachelib in d:\\special\\documatic\\.venv\\lib\\site-packages (from flask-session) (0.13.0)\n",
      "Requirement already satisfied: numpy in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: torch==2.6.0+cu118 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (2.6.0+cu118)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: filelock in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (3.3)\n",
      "Requirement already satisfied: fsspec in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch==2.6.0+cu118->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0+cu118->torchvision) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\special\\documatic\\.venv\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sqlalchemy>=2.0.16->flask-sqlalchemy) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qwen-vl-utils in d:\\special\\documatic\\.venv\\lib\\site-packages (0.0.10)\n",
      "Requirement already satisfied: transformers in d:\\special\\documatic\\.venv\\lib\\site-packages (4.48.2)\n",
      "Requirement already satisfied: accelerate in d:\\special\\documatic\\.venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: pdf2image in d:\\special\\documatic\\.venv\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: bitsandbytes in d:\\special\\documatic\\.venv\\lib\\site-packages (0.45.1)\n",
      "Requirement already satisfied: av in d:\\special\\documatic\\.venv\\lib\\site-packages (from qwen-vl-utils) (14.1.0)\n",
      "Requirement already satisfied: packaging in d:\\special\\documatic\\.venv\\lib\\site-packages (from qwen-vl-utils) (24.2)\n",
      "Requirement already satisfied: pillow in d:\\special\\documatic\\.venv\\lib\\site-packages (from qwen-vl-utils) (11.0.0)\n",
      "Requirement already satisfied: requests in d:\\special\\documatic\\.venv\\lib\\site-packages (from qwen-vl-utils) (2.32.3)\n",
      "Requirement already satisfied: filelock in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in d:\\special\\documatic\\.venv\\lib\\site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from accelerate) (2.6.0+cu118)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\special\\documatic\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->qwen-vl-utils) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->qwen-vl-utils) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->qwen-vl-utils) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->qwen-vl-utils) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in d:\\special\\documatic\\.venv\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: sentence-transformers in d:\\special\\documatic\\.venv\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy in d:\\special\\documatic\\.venv\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: packaging in d:\\special\\documatic\\.venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (4.48.2)\n",
      "Requirement already satisfied: tqdm in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (2.6.0+cu118)\n",
      "Requirement already satisfied: scikit-learn in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in d:\\special\\documatic\\.venv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\special\\documatic\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\special\\documatic\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\special\\documatic\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting Werkzeug>=3.1 (from flask)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Jinja2>=3.1.2 (from flask)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting itsdangerous>=2.2 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting blinker>=1.9 (from flask)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting colorama (from click>=8.1.3->flask)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: MarkupSafe, itsdangerous, colorama, blinker, Werkzeug, Jinja2, click, flask\n",
      "Successfully installed Jinja2-3.1.4 MarkupSafe-2.1.5 Werkzeug-3.1.3 blinker-1.9.0 click-8.1.8 colorama-0.4.6 flask-3.1.0 itsdangerous-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in d:\\special\\documatic\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in d:\\special\\documatic\\.venv\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in d:\\special\\documatic\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\special\\documatic\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install flask flask-sqlalchemy flask-session flask-login torchvision\n",
    "%pip install qwen-vl-utils transformers accelerate pdf2image bitsandbytes\n",
    "%pip install faiss-cpu sentence-transformers numpy\n",
    "%pip install --ignore-installed flask\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !apt update\n",
    "# !apt install poppler-utils -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139a497d-f336-471a-bffb-16a14d77f04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SPECIAL\\Documatic\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from accelerate import Accelerator\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "# from llm_axe.agents import OnlineAgent\n",
    "from pathlib import Path\n",
    "import os\n",
    "from flask import Flask, request, jsonify, send_file, abort\n",
    "from werkzeug.utils import secure_filename\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39ee8cb-717b-4fd2-853d-5e5fe3565a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2289d5fe-852f-4715-b10a-363696b750e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# default: Load the model on the available device(s)\n",
    "# min_pixels = 256 * 28 * 28\n",
    "# max_pixels = 1280 * 28 * 28\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\", \n",
    "    # torch_dtype=\"float16\", \n",
    "    device_map={\"\": device}, \n",
    "    load_in_8bit=True\n",
    ")\n",
    "\n",
    "# We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "# model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "#     \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "# default processer\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "\n",
    "# The default range for the number of visual tokens per image in the model is 4-16384. You can set min_pixels and max_pixels according to your needs, such as a token count range of 256-1280, to balance speed and memory usage.\n",
    "# min_pixels = 256*28*28\n",
    "# max_pixels = 1280*28*28\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed740a8b-e87f-4e69-81da-07460bdef987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLiteFileSummaryStorage:\n",
    "    \"\"\"Store file summaries using SQLite\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path=\"file_summaries.db\"):\n",
    "        self.db_path = db_path\n",
    "        self._ensure_database_exists()\n",
    "    \n",
    "    def _ensure_database_exists(self):\n",
    "        \"\"\"Create database and table if they don't exist\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS file_summaries (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                device_id TEXT,\n",
    "                filename TEXT,\n",
    "                filepath TEXT,\n",
    "                summary TEXT,\n",
    "                ocr TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def save_summary(self, device_id, filename, filepath, summary, ocr):\n",
    "        \"\"\"Save a file summary\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                INSERT OR REPLACE INTO file_summaries (device_id, filename, filepath, summary, ocr)\n",
    "                VALUES (?, ?, ?, ?, ?)\n",
    "            ''', (device_id, filename, filepath, summary, ocr))\n",
    "            \n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving summary: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_summary(self, filename):\n",
    "        \"\"\"Retrieve a file summary\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                SELECT summary FROM file_summaries\n",
    "                WHERE filename = ?\n",
    "            ''', (filename,))\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "            conn.close()\n",
    "            \n",
    "            return result[0] if result else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving summary: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_summary_with_device_id(self, device_id):\n",
    "        \"\"\"Retrieve a file summary\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                SELECT id, filename, filepath FROM file_summaries\n",
    "                WHERE device_id = ?\n",
    "            ''', (device_id,))\n",
    "            \n",
    "            result = cursor.fetchall()\n",
    "            conn.close()\n",
    "            \n",
    "            return result if result else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving summary: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_summary_with_id(self, id):\n",
    "        \"\"\"Retrieve a file summary\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                SELECT filename, filepath FROM file_summaries\n",
    "                WHERE id = ?\n",
    "            ''', (id,))\n",
    "            \n",
    "            result = cursor.fetchone()\n",
    "            conn.close()\n",
    "            \n",
    "            return result if result else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving summary: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_all_summaries(self):\n",
    "        \"\"\"Get all stored summaries\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            cursor.execute('''\n",
    "                SELECT filename, filepath, summary, timestamp \n",
    "                FROM file_summaries\n",
    "            ''')\n",
    "            \n",
    "            results = cursor.fetchall()\n",
    "            conn.close()\n",
    "            \n",
    "            return {row[0]: {\n",
    "                'filepath': row[1],\n",
    "                'summary': row[2],\n",
    "                'timestamp': row[3]\n",
    "            } for row in results}\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving summaries: {e}\")\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ababfcd4-05a5-4533-8719-6b796f9ba227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_format(messages: list[dict]) -> bool:\n",
    "    \"\"\"\n",
    "    Checks if the messages are already in the correct format.\n",
    "    \n",
    "    Correct format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"message text\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Args:\n",
    "        messages (list[dict]): List of message dictionaries to validate\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if format is correct, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(messages, list):\n",
    "            return False\n",
    "            \n",
    "        for message in messages:\n",
    "            # Check if basic structure exists\n",
    "            if not isinstance(message, dict):\n",
    "                return False\n",
    "                \n",
    "            if 'role' not in message or 'content' not in message:\n",
    "                return False\n",
    "                \n",
    "            # Check role\n",
    "            if not isinstance(message['role'], str):\n",
    "                return False\n",
    "                \n",
    "            # Check content structure\n",
    "            content = message['content']\n",
    "            if not isinstance(content, list):\n",
    "                return False\n",
    "                \n",
    "            # Validate each content item\n",
    "            for item in content:\n",
    "                if not isinstance(item, dict):\n",
    "                    return False\n",
    "                    \n",
    "                if 'type' not in item or 'text' not in item:\n",
    "                    return False\n",
    "                    \n",
    "                if item['type'] != 'text':\n",
    "                    return False\n",
    "                    \n",
    "                if not isinstance(item['text'], str):\n",
    "                    return False\n",
    "                    \n",
    "        return True\n",
    "        \n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def convert_message_format(messages: list[dict]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Converts messages from simple format to the structured format required by the model.\n",
    "    \n",
    "    Input format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"message text\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Output format:\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"message text\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    Args:\n",
    "        messages (list[dict]): List of message dictionaries in simple format\n",
    "        \n",
    "    Returns:\n",
    "        list[dict]: List of message dictionaries in structured format\n",
    "    \"\"\"\n",
    "    converted_messages = []\n",
    "    \n",
    "    for message in messages:\n",
    "        # Handle case where content is already in the correct format\n",
    "        if isinstance(message.get('content'), list):\n",
    "            converted_messages.append(message)\n",
    "            continue\n",
    "            \n",
    "        # Convert simple string content to structured format\n",
    "        converted_message = {\n",
    "            \"role\": message[\"role\"],\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": message[\"content\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        converted_messages.append(converted_message)\n",
    "    \n",
    "    return converted_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84bdf40f-197b-4c47-ba01-f38073469623",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JARVIS():\n",
    "\n",
    "    # Your ask function will always receive a list of prompts\n",
    "    # The prompts are in open ai prompt format\n",
    "    #  example: {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "    # If your model supports json format, use the format parameter to specify that to your model.\n",
    "    def ask(self, messages:list, format:str=\"\", temperature:float=0.8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prompts (list): A list of prompts to ask.\n",
    "            format (str, optional): The format of the response. Use \"json\" for json. Defaults to \"\".\n",
    "            temperature (float, optional): The temperature of the LLM. Defaults to 0.8.\n",
    "        \"\"\"\n",
    "        correct_format = is_correct_format(messages)\n",
    "        if not correct_format:\n",
    "            messages = convert_message_format(messages)\n",
    "        # Preparation for inference\n",
    "        text = processor.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            videos=video_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        # Inference: Generation of the output\n",
    "        generated_ids = model.generate(**inputs, \n",
    "                                       max_new_tokens=4096,           # Adjust based on your desired summary length\n",
    "                                       temperature=0.2,          # Balances diversity and coherence\n",
    "                                       top_p=0.9,                # Top-p sampling for additional control\n",
    "                                       do_sample=True,           # Enables sampling for diversity\n",
    "                                       repetition_penalty=1.1    # Avoids repetitive outputs\n",
    "                                       )\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "        )\n",
    "        if not correct_format:\n",
    "            return output_text[0]\n",
    "        return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab6585f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\SPECIAL\\Documatic\\poppler\\Library\n"
     ]
    }
   ],
   "source": [
    "import os, platform, subprocess\n",
    "\n",
    "def add_poppler_to_path():\n",
    "    poppler_dir = os.path.join(os.getcwd(), \"poppler\\\\Library\")\n",
    "    print(poppler_dir)\n",
    "    system = platform.system().lower()\n",
    "    if system == \"windows\":\n",
    "        poppler_bin_dir = os.path.join(poppler_dir, \"bin\") # Poppler DLLs usually in bin folder\n",
    "        # if hasattr(os, \"add_dll_directory\"): # Python 3.8+\n",
    "        #     os.add_dll_directory(poppler_bin_dir)\n",
    "        #     print(\"Here\")\n",
    "        # else:\n",
    "        os.environ[\"PATH\"] = poppler_bin_dir + os.pathsep + os.environ[\"PATH\"]\n",
    "    elif system in (\"linux\", \"darwin\"):\n",
    "        lib_path_var = \"LD_LIBRARY_PATH\" if system == \"linux\" else \"DYLD_LIBRARY_PATH\"\n",
    "        poppler_lib_dir = os.path.join(poppler_dir, system, \"lib\")\n",
    "        if lib_path_var in os.environ:\n",
    "            os.environ[lib_path_var] = poppler_lib_dir + os.pathsep + os.environ[lib_path_var]\n",
    "        else:\n",
    "            os.environ[lib_path_var] = poppler_lib_dir\n",
    "    else:\n",
    "        raise OSError(\"Unsupported operating system\")\n",
    "\n",
    "# Call this function BEFORE importing any libraries that depend on Poppler\n",
    "add_poppler_to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aae74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "\n",
    "def optimize_images(filepath, output_folder, dpi=150, compression=\"webp\"):\n",
    "    \"\"\"Convert PDF to optimized images for OCR.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    images = convert_from_path(filepath, dpi=dpi)\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        # Convert to grayscale\n",
    "        img = img.convert(\"L\")\n",
    "        \n",
    "        # Trim whitespace\n",
    "        img = ImageOps.expand(ImageOps.crop(img, border=10), border=5)  # Adjust for better trimming\n",
    "\n",
    "        # Save with compression\n",
    "        output_path = os.path.join(output_folder, f\"page_{i+1}.{compression}\")\n",
    "        img.save(output_path, format=compression.upper(), quality=80 if compression == \"webp\" else None)\n",
    "\n",
    "        print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d0acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText():\n",
    "    text = \"\"\n",
    "    import os\n",
    "    image_files = sorted([f for f in os.listdir(\"temporary\") if f.endswith(('.png', '.webp', '.jpg'))])\n",
    "    from easyocr import Reader\n",
    "\n",
    "    # Initialize the Reader (specify the languages you need, e.g., English and Hindi)\n",
    "    reader = Reader(['en'], gpu=True)  # Set gpu=True if you have a GPU\n",
    "\n",
    "    for file in image_files:\n",
    "        img_path = \"temporary/\" + file\n",
    "        # Perform OCR\n",
    "        results = reader.readtext(img_path)\n",
    "\n",
    "        # Display results\n",
    "        t=f\"{file}:\\n\\n\"\n",
    "        for (bbox, tex, confidence) in results:\n",
    "            t += tex + \"\\n\"\n",
    "        text += t + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6adc0991-c74e-4dce-93e8-08e3cb614d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "db = SQLiteFileSummaryStorage()\n",
    "jarvis = JARVIS()\n",
    "def generate_summary(filepath, name, query):\n",
    "    content = []\n",
    "    img_out = \"temporary\"\n",
    "    optimize_images(filepath, img_out)\n",
    "    ocr = getText()\n",
    "    image_files = sorted([f for f in os.listdir(img_out) if f.endswith(('.png', '.webp', '.jpg'))])\n",
    "    i = 0\n",
    "    batches = (len(image_files) // 5) + (1 if len(image_files) % 5 != 0 else 0)\n",
    "    previous = \"\"\n",
    "    while image_files:\n",
    "        length = len(image_files)\n",
    "        for j in range(0, min(5, length)):\n",
    "            content.append({\n",
    "                    \"type\":\"image\",\n",
    "                    \"image\":\"temporary/\"+image_files.pop(0),\n",
    "                    \"resized_height\": 280,\n",
    "                    \"resized_width\": 420,\n",
    "                })\n",
    "   \n",
    "        content.append({\"type\": \"text\", \"text\": f\"\"\"[INSTRUCTION]\n",
    "You are a document intelligence assistant specializing in structured, detailed, and searchable summaries. You MUST always output in the exact format provided below, even if the document has little content.\n",
    "\n",
    "[OUTPUT FORMAT]\n",
    "1. **Core Summary:** [Brief summary of the document]\n",
    "2. **Document Details:**\n",
    "   - **Primary Purpose:** [Function of the document]\n",
    "   - **Document Type:** [Type of document]\n",
    "   - **Target Audience:** [Intended users]\n",
    "3. **Extracted Details:** \n",
    "   - **Names:** [List of names]\n",
    "   - **Numbers:** [List of numbers, dates, IDs]\n",
    "   - **Addresses:** [If available]\n",
    "   - **Keywords/Phrases:** [Relevant search terms]\n",
    "4. **Alternate Use Cases:** \n",
    "   - [List at least 3 alternative ways this document could be useful]\n",
    "5. **Searchable Contexts:** \n",
    "   - \"This document is relevant when searching for...\"\n",
    "6. **Search Keywords:** \n",
    "   - [List 12-15 keywords]\n",
    "7. **Alternate Search Phrases:**  \n",
    "   - [\"Example query 1\", \"Example query 2\"]\n",
    "\n",
    "[CONSTRAINTS]\n",
    "- **Never return an incomplete output.**\n",
    "- **If there is not enough information, reinstate the information using more generalised words, statemens and phrases and still fill all the sections**\n",
    "- **Do not skip sections, always provide placeholders.** \n",
    "- **If a previous summary is provided, Improve on it with the new content found new next batch of images.**  \n",
    "\n",
    "\n",
    "[User Input]\n",
    "File: A set of images/PDF pages from a document (processed in batches).\n",
    "User Description: {query}.\n",
    "File Name: {name}.\n",
    "Batch: {i+1}/{batches}\n",
    "{\"Previous summary: \" + previous if i != 0 else \"\"}\n",
    "\"\"\"})\n",
    "#Batch Info: {batch}/{total} (if applicable).\n",
    "#     content.append({\"type\": \"text\", \"text\": f\"\"\"You are a document summarization assistant. Your task is to create a comprehensive, searchable summary of a file based on its contents and provided description. Follow this structured approach:\n",
    "# GUIDELINES:\n",
    "\n",
    "# Focus on discoverability - include terms users might search for\n",
    "# Incorporate both technical and layman's terms\n",
    "# Add every keyword like any names, phrases etc.\n",
    "# Consider different ways users might try to find this document\n",
    "# Include crucial context from both the file content and user description\n",
    "# Add industry-standard terminology where relevant\n",
    "# Consider various use cases and access patterns\n",
    "# Maintain factual accuracy while optimizing for searchability\n",
    "\n",
    "# Now, analyze the provided file and description to generate a comprehensive summary like this, Do not exceed the numbers mentioned:\n",
    "\n",
    "# INPUTS:\n",
    "# File: attached pages as images. treat them combined as single file\n",
    "# User Description: {query}\n",
    "# File name: {name}\n",
    "# OCR content: {ocr}\n",
    "# Generate a summary in the following format:\n",
    "# CORE SUMMARY (2-3 sentences):\n",
    "# [Provide a clear, concise overview of the main content and purpose of the file]\n",
    "\n",
    "# DOCUMENT TYPE & PURPOSE:\n",
    "# - Primary Purpose: [Main function/goal of the document]\n",
    "# - Document Category: [Report/Specification/Manual/Analysis/etc.]\n",
    "# - Target Audience: [Intended readers/users]\n",
    "\n",
    "# OCR HIGHLIGHTS:\n",
    "# Summarize the OCR content and maintain all the important info\n",
    "\n",
    "# KEY TOPICS:\n",
    "# - [Topic 1]\n",
    "# - [Topic 2]\n",
    "# - [Topic 3]\n",
    "# [List 3-5 main topics covered]\n",
    "\n",
    "# REFERENCE CONTEXTS:\n",
    "# \"This file would be relevant when looking for...\"\n",
    "# - [Scenario 1]\n",
    "# - [Scenario 2]\n",
    "# - [Scenario 3]\n",
    "# [List 3-4 specific use cases or scenarios]\n",
    "\n",
    "# ADDITIONAL CONTEXT FROM USER DESCRIPTION:\n",
    "# [Integrate any unique insights or context from the user's description that aren't apparent from the file content alone]\n",
    "\n",
    "# SEARCH KEYWORDS:\n",
    "# [List 8-12 relevant search terms, including:\n",
    "# - Common synonyms\n",
    "# - Technical terms\n",
    "# - Related concepts\n",
    "# - Alternative phrasings\n",
    "# Separate with commas]\n",
    "\n",
    "# IMPORTANT INFO:\n",
    "# [List all the specific things in the document, including:\n",
    "# - Names (places, people, emails, objects, anything)\n",
    "# - Dates, Numbers\n",
    "# - phrases\n",
    "# Separate with commas]\n",
    "\n",
    "# ALTERNATE SEARCH PHRASES:\n",
    "# [List different phrases a user can use to look for this document, keep it very generalised, like any alternate use case except the primary one]\n",
    "\n",
    "# \"\"\"})\n",
    "        print(content)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content,\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        output_text = jarvis.ask(messages)\n",
    "        previous = output_text\n",
    "        content = []\n",
    "        i += 1\n",
    "    for page in image_files:\n",
    "        if os.path.exists(\"temporary/\"+page):\n",
    "            os.remove(\"temporary/\"+page)\n",
    "    return previous, ocr\n",
    "\n",
    "def get_file(query):\n",
    "    jarvis = JARVIS()\n",
    "    summaries = db.get_all_summaries()\n",
    "    print(len(summaries.items()))\n",
    "    print(query)\n",
    "    scores = \"\"\n",
    "    for filename, data in summaries.items():\n",
    "        summary = data['summary']\n",
    "        path = data['filepath']\n",
    "        print(\"Summary: \" + summary)\n",
    "        print(\"Query: \" + query)\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"\"\"You are a document matching expert. Analyze how well a query matches a given summary and provide a single confidence score from 0-100.\n",
    "\n",
    "Scoring Criteria:\n",
    "1. Exact Keyword Matches (40 points max):\n",
    "   - Exact matches of query terms (case-insensitive)\n",
    "   - Multiple occurrences increase score\n",
    "   - Technical/specific terms worth more than common words\n",
    "   - Title/key position matches worth more\n",
    "\n",
    "2. Keyword Variations (30 points max):\n",
    "   - Plurals/singulars (car/cars)\n",
    "   - Common synonyms (vehicle/automobile)\n",
    "   - Word forms (run/running/ran)\n",
    "   - Compound variations (healthcare/health care)\n",
    "\n",
    "3. Semantic Relevance (20 points max):\n",
    "   - Topic and concept alignment\n",
    "   - Context relevance\n",
    "\n",
    "4. Additional Factors (10 points max):\n",
    "   - Term proximity\n",
    "   - Information relevance\n",
    "\n",
    "Query: {query}\n",
    "Summary: {summary}\n",
    "\n",
    "Follow these steps silently:\n",
    "1. Check exact keyword matches\n",
    "2. Find keyword variations\n",
    "3. Assess semantic alignment\n",
    "4. Consider additional factors\n",
    "5. Sum up scores\n",
    "\n",
    "Output only this format:\n",
    "Confidence Score: <0-100>\"\"\"},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        output_text = jarvis.ask(messages)\n",
    "        scores += f\"({filename},{path},{str(output_text[0])})\\n\"\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3851ad07-7d80-453e-8d53-7db6b6a3699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: temporary\\page_1.webp\n",
      "Saved: temporary\\page_2.webp\n",
      "[{'type': 'image', 'image': 'temporary/page_1.webp', 'resized_height': 280, 'resized_width': 420}, {'type': 'image', 'image': 'temporary/page_2.webp', 'resized_height': 280, 'resized_width': 420}, {'type': 'text', 'text': 'You are a document intelligence assistant specializing in **multi-page document processing**. Your task is to analyze **batches of document pages** and generate a **structured, detailed, and searchable summary** for retrieval using natural language queries.\\n\\n# TASK:\\n1. **Process Document Pages in Batches**:  \\n   - The document will be provided in multiple parts (batches of pages).  \\n   - Ensure **consistency across batches** while summarizing.  \\n   - Accumulate important details across batches to **build a comprehensive summary**.  \\n\\n2. **Preserve Key Details**:  \\n   - Include all identifiable details (names, numbers, dates, keywords).  \\n   - Ensure extracted details remain **consistent and linked** across batches.  \\n\\n3. **Maintain Context Across Batches**:  \\n   - Each batch adds new information—**integrate it with previously processed content**.  \\n   - If this is **not the first batch**, continue refining the summary rather than restarting.  \\n\\n4. **Maximize Searchability**:  \\n   - Generate a structured summary that makes it easy for users to find this document via natural queries.  \\n   - Include potential **alternate phrasings and use cases** to enhance retrieval.  \\n\\n5. **Generate Searchable Keywords & Queries**:  \\n   - Provide multiple ways users might phrase their search.  \\n\\n---\\n\\n# **REQUIRED OUTPUT**  \\n### **1. CORE SUMMARY (2-3 sentences)**  \\n- A brief but informative description of the document’s purpose and content.  \\n\\n### **2. DOCUMENT DETAILS**  \\n- **Primary Purpose:** [What this document is meant for]  \\n- **Document Type:** [e.g., ID card, contract, report]  \\n- **Target Audience:** [Who would use this document]  \\n\\n### **3. EXTRACTED DETAILS (MANDATORY)**  \\n- **Names:** [People, organizations, places]  \\n- **Numbers:** [ID numbers, reference numbers, dates, monetary values]  \\n- **Addresses:** [If available]  \\n- **Keywords/Phrases:** [Important terms that improve retrieval]  \\n\\n### **4. ALTERNATE USE CASES**  \\n- Identify different scenarios where this document might be useful.  \\n\\n### **5. SEARCHABLE CONTEXTS**  \\n- \"This document is relevant when searching for...\"  \\n- Provide at least **3-5 contexts** where a user might look for this.  \\n\\n### **6. SEARCH KEYWORDS**  \\n- List **12-15 keywords** users might use to find this document.  \\n\\n### **7. ALTERNATE SEARCH PHRASES**  \\n- Example queries users might enter when looking for this document.  \\n\\n\\nInputs:\\nFile: A set of images/PDF pages from a document (processed in batches).\\nUser Description: My airline ticket.\\nFile Name: Flair Airlines.pdf.\\nBatch: 1/1\\n\\n'}]\n",
      "('## Document Summary\\n\\nThe document contains essential details about a Flair Airlines flight itinerary for May 9th, 2022. The primary purpose of this document is to provide travelers with all necessary information regarding their flight, including booking number, departure and arrival times, seat assignments, and total cost. The target audience includes passengers who need to confirm their travel plans or make changes to their flights.\\n\\n### Document Details\\n\\n#### Primary Purpose: To confirm travel plans or make changes to Flair Airlines flights.\\n\\n#### Document Type: Itinerary.\\n\\n#### Target Audience: Passengers traveling on Flair Airlines.\\n\\n#### Extracted Details:\\n\\n| Name | Number | Address |\\n|------|--------|---------|\\n| John Doe | 1234567890 | 123 Main St, Anytown, USA |\\n| Jane Smith | 9876543210 | 456 Elm St, Anytown, USA |\\n\\n#### Alternate Use Cases:\\n\\n1. Checking flight status.\\n2. Confirming seat availability.\\n3. Making changes to flight details.\\n4. Requesting a refund or cancellation.\\n5. Requesting assistance with baggage handling.\\n\\n#### Searchable Contexts:\\n\\n1. \"Flair Airlines flight itinerary for May 9th, 2022.\"\\n2. \"Flight details for John Doe\\'s trip.\"\\n3. \"Seat assignment for Jane Smith\\'s flight.\"\\n\\n#### Search Keywords:\\n\\n1. Flair Airlines flight itinerary.\\n2. May 9th, 2022 flight details.\\n3. John Doe\\'s travel confirmation.\\n4. Jane Smith\\'s flight change request.\\n\\n#### Alternate Search Phrases:\\n\\n1. \"Flair Airlines flight booking for May 9th, 2022.\"\\n2. \"Jane Smith\\'s flight details for May 9th, 2022.\"\\n3. \"John Doe\\'s flight update for May 9th, 2022.\"', 'page_1.webp:\\n\\n5/3/23, 12.46 AM\\nFlair Airlines\\nflair\\nairlines\"\\nyour itinerary\\nbooking number bShu3x\\nbelow you will find all of the details for this itinerary\\nwednesday, may 10, 2023\\nbooking contact\\ntoronto\\n2\\npassengers\\nwinnipeg\\nemail\\npearson\\n06:30\\n08:10\\n0\\nchange\\nywg\\ndishulbansal@gmail.com\\ncustomizations\\nYyZ\\nflight: f8 643\\nprimary phone:\\ndetails\\n6476161501\\nair transportation charges (atc)\\ntaxes, fees and charges (tfc)\\n2 * econo promo\\ncaS1.24)\\ncaS2.48\\n2 x air traveller security charge\\ncaS14.24\\npayment(s):\\ncaS7.12)\\n2 x airport improvement fee\\ncaS70.00\\nVISA\\ncaS35.00)\\nmethod:\\nvisa\\ntaxes\\ncaS11.28\\ncard:\\n453734\\n#6000\\n5010\\ndate & time:\\n03/05/2023 00:20\\ntotal atc\\ncas2.48\\ntotal tfc\\ncaS95.52\\namount\\ncaS197.40\\njourney total\\ncas98.00\\ntotal booking payment\\ncaS197.40\\nthursday, may 11, 2023\\ntoronto\\npassengers\\nwinnipeg\\npearson\\n20:35\\nOo:05\\nchange\\nywg\\ncustomizations\\nYyZ\\nflight: f8 640\\ndetails\\nair transportation charges (atc)\\ntaxes, fees and charges (tfc)\\n2 * econo promo\\ncaS1.55)\\ncaS3.10\\n2 x air traveller security charge\\ncaS14.24\\ncaS7.12)\\n2 x airport improvement fee\\ncaS76.00\\ncaS38.00)\\ntaxes\\ncaS6.06\\ntotal atc\\ncaS3.10\\ntotal tfc\\ncas96.30\\njourney total\\ncas99.40\\npassengers\\nadult\\nadult\\nmr vikas kumar\\nmr dishu bansal\\n14 february 1979\\n8 may 2002\\ncontact details\\ncontact details\\ne-mail\\ndishulbansal@gmail.com\\ne-mail\\ndishulbansal@gmailcom\\nphone\\n+1647 616 1501\\nmobile\\n+1647 616 1501\\nmobile\\n+1647 616 1501\\nseat selection\\nseat selection\\nflight 1/2\\nhttps:Ilres flyflair comlresIBSHU3Xlitinerary?lastName-Kumar\\n1/2\\n\\npage_2.webp:\\n\\n5/3/23, 12.46 AM\\nFlair Airlines\\nflight 1/2\\nYYZ\\nywg\\nnone\\nYYZ\\nywg\\nnone\\nflight 2/2\\nflight 2/2\\nywg\\nYyZ\\nnone\\nywg\\nYyZ\\nnone\\nancillaries\\nancillaries\\nflight 1/2\\nflight 1/2\\nYZ\\nywg\\nnone\\nYYZ\\nywg\\nnone\\nflight 2/2\\nflight 2/2\\nywg\\nYyZ\\nnone\\nywg\\nYyZ\\nnone\\nhttps:Ilres flyflair comlresIBSHU3Xlitinerary?lastName-Kumar\\n212\\n\\n')\n"
     ]
    }
   ],
   "source": [
    "summary = generate_summary(\"d:/SPECIAL/Documatic/Flair Airlines.pdf\", \"Flair Airlines.pdf\", \"My airline ticket\")\n",
    "print(summary)\n",
    "# db.save_summary(\"Indian License.pdf\", \"Indian License.pdf\", summary[0])\n",
    "# print(get_file(\"my indian driving license\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77b04c2-650b-44fb-a987-faf84028e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "class DocumentSearchSystem:\n",
    "    def __init__(self, index_file: str = \"faiss_index.bin\", metadata_file: str = \"metadata.json\"):\n",
    "        # Initialize the Sentence-BERT model for embedding generation\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # File paths for persistence\n",
    "        self.index_file = index_file\n",
    "        self.metadata_file = metadata_file\n",
    "        self.database = SQLiteFileSummaryStorage()\n",
    "\n",
    "        # List to store document metadata\n",
    "        self.documents = []\n",
    "\n",
    "        # Load or initialize FAISS index\n",
    "        self.dimension = 384  # Embedding size of 'all-MiniLM-L6-v2'\n",
    "        self.index = self._load_or_initialize_index()\n",
    "        \n",
    "        # # Load document metadata\n",
    "        # self._load_metadata()\n",
    "        \n",
    "    def _load_or_initialize_index(self):\n",
    "        \"\"\"Load the FAISS index from disk or initialize a new one if not found.\"\"\"\n",
    "        if os.path.exists(self.index_file):\n",
    "            index = faiss.read_index(self.index_file)\n",
    "            print(\"FAISS index loaded from disk.\")\n",
    "        else:\n",
    "            index = faiss.IndexFlatL2(self.dimension)  # L2 (Euclidean) index\n",
    "            print(\"New FAISS index created.\")\n",
    "        return index\n",
    "\n",
    "    # def _load_metadata(self):\n",
    "    #     \"\"\"Load document metadata from JSON file if it exists.\"\"\"\n",
    "    #     if os.path.exists(self.metadata_file):\n",
    "    #         with open(self.metadata_file, \"r\") as f:\n",
    "    #             self.documents = json.load(f)\n",
    "    #         print(\"Document metadata loaded from disk.\")\n",
    "    #     else:\n",
    "    #         self.documents = []\n",
    "    \n",
    "    def _save_index_and_metadata(self):\n",
    "        \"\"\"Save the FAISS index and document metadata to disk.\"\"\"\n",
    "        # Save the FAISS index\n",
    "        faiss.write_index(self.index, self.index_file)\n",
    "        \n",
    "        # Save the metadata as JSON\n",
    "        # with open(self.metadata_file, \"w\") as f:\n",
    "        #     json.dump(self.documents, f)\n",
    "        \n",
    "        print(\"FAISS index and document metadata saved to disk.\")\n",
    "\n",
    "    def add_document(self, id: str, file_name: str, file_path: str, summary: str, ocr:str):\n",
    "        \"\"\"Add a document to the FAISS index and store its metadata.\"\"\"\n",
    "        # Generate the embedding for the summary\n",
    "        final = \"OCR:\\n\" + ocr + \"\\n\\nSummary:\\n\" + summary\n",
    "        embedding = self.model.encode(final).astype(np.float32).reshape(1, -1)\n",
    "        \n",
    "        # Add embedding to FAISS index\n",
    "        self.index.add(embedding)\n",
    "        \n",
    "        # Store metadata in documents list\n",
    "        # self.documents.append({\n",
    "        #     \"id\": id,\n",
    "        #     \"file_name\": file_name,\n",
    "        #     \"file_path\": file_path,\n",
    "        #     \"summary\": summary\n",
    "        # })\n",
    "        self.database.save_summary(device_id=id, filename=file_name, filepath=file_path, summary=summary, ocr=ocr)\n",
    "        \n",
    "        print(f\"Added document: {file_name}\")\n",
    "        \n",
    "        # Save index and metadata\n",
    "        self._save_index_and_metadata()\n",
    "\n",
    "    def search_documents(self, doc_id: str, query: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"Search for documents matching the query and return top_k results.\"\"\"\n",
    "        # Generate embedding for the query\n",
    "        query_embedding = self.model.encode(query).astype(np.float32).reshape(1, -1)\n",
    "    \n",
    "        documents = self.database.get_summary_with_device_id(doc_id)\n",
    "        print(\"Docs: \" + str(documents))\n",
    "\n",
    "        # Get indices of documents with matching doc_id\n",
    "        matching_indices = [doc[0] for i, doc in enumerate(documents)]\n",
    "        print(\"Result: \" + str(matching_indices))\n",
    "        \n",
    "        if not matching_indices:\n",
    "            return []  # Return empty list if no documents match the ID\n",
    "        \n",
    "        # Create a subset index with only the matching documents\n",
    "        subset_index = faiss.IndexFlatL2(self.dimension)\n",
    "        subset_embeddings = np.vstack([\n",
    "            self.index.reconstruct(i) for i in matching_indices\n",
    "        ])\n",
    "        subset_index.add(subset_embeddings)\n",
    "        print(\"Subset: \" + str(subset_embeddings.shape))\n",
    "        \n",
    "        # Perform search in subset index\n",
    "        distances, indices = subset_index.search(query_embedding, min(top_k, len(matching_indices)))\n",
    "        print(\"Indices: \" + str(indices))\n",
    "        \n",
    "        # Retrieve and return matching documents\n",
    "        results = []\n",
    "        for idx, distance in zip(indices[0], distances[0]):\n",
    "            if idx != -1:  # Ensure valid index\n",
    "                # doc = self.documents[idx]\n",
    "                # doc['score'] = 1 / (1 + distance)  # Convert distance to similarity score\n",
    "                # results.append(doc)\n",
    "\n",
    "                original_idx = matching_indices[idx]\n",
    "                doc = list(self.database.get_summary_with_id(original_idx + 1))\n",
    "                #doc = self.documents[original_idx].copy()  # Copy the metadata\n",
    "                doc.append(float(1 / (1 + distance)))  # Convert to Python float\n",
    "                results.append(doc)\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf0fe539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded from disk.\n",
      "Added document: File 1\n",
      "FAISS index and document metadata saved to disk.\n",
      "Result: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['File 1', 'Path 1', 0.5000023245811462],\n",
       " ['File 1', 'Path 1', 0.44425609707832336],\n",
       " ['File 1', 'Path 1', 0.44425609707832336]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = DocumentSearchSystem()\n",
    "system.add_document(\"Device 1\", \"File 1\", \"Path 1\", \"Summary 1\", \"OCR 1\")\n",
    "system.search_documents(\"Device 1\", \"Query 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869900f-a0a6-45cd-896f-602f3e109df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded from disk.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.2.14:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n",
      "Search id: BE418B70-D927-EB11-80D9-089798CE56FE, Text: resume\n",
      "Docs: [(1, 'Coop Work Permit.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\Coop Work Permit.pdf'), (2, 'Coop Work Permit.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\Coop Work Permit.pdf'), (3, 'Smart Serve.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\Smart Serve.pdf'), (4, 'OFHC_Food Handler Certificate.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\OFHC_Food Handler Certificate.pdf'), (5, 'Indian License.pdf', 'D:\\\\Google Drive Backup\\\\Indian License.pdf'), (6, 'Flair Airlines.pdf', 'D:\\\\SPECIAL\\\\Documatic\\\\Flair Airlines.pdf'), (7, 'Dishu_Bansal_Software_Engineer.pdf', 'D:\\\\Full time\\\\ElectricMind\\\\Dishu_Bansal_Software_Engineer.pdf')]\n",
      "Result: [1, 2, 3, 4, 5, 6, 7]\n",
      "Subset: (7, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [30/Mar/2025 22:43:55] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices: [[3 5 0]]\n",
      "[['Indian License.pdf', 'D:\\\\Google Drive Backup\\\\Indian License.pdf', 0.37955552339553833], ['Dishu_Bansal_Software_Engineer.pdf', 'D:\\\\Full time\\\\ElectricMind\\\\Dishu_Bansal_Software_Engineer.pdf', 0.378853440284729], ['Coop Work Permit.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\Coop Work Permit.pdf', 0.3741218149662018]]\n",
      "Here\n",
      "Search id: BE418B70-D927-EB11-80D9-089798CE56FE, Text: my resume\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [30/Mar/2025 22:44:32] \"POST /upload HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: [(1, 'Coop Work Permit.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\Coop Work Permit.pdf'), (2, 'Coop Work Permit.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\Coop Work Permit.pdf'), (3, 'Smart Serve.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\Smart Serve.pdf'), (4, 'OFHC_Food Handler Certificate.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\OFHC_Food Handler Certificate.pdf'), (5, 'Indian License.pdf', 'D:\\\\Google Drive Backup\\\\Indian License.pdf'), (6, 'Flair Airlines.pdf', 'D:\\\\SPECIAL\\\\Documatic\\\\Flair Airlines.pdf'), (7, 'Dishu_Bansal_Software_Engineer.pdf', 'D:\\\\Full time\\\\ElectricMind\\\\Dishu_Bansal_Software_Engineer.pdf')]\n",
      "Result: [1, 2, 3, 4, 5, 6, 7]\n",
      "Subset: (7, 384)\n",
      "Indices: [[5 3 0]]\n",
      "[['Dishu_Bansal_Software_Engineer.pdf', 'D:\\\\Full time\\\\ElectricMind\\\\Dishu_Bansal_Software_Engineer.pdf', 0.39481064677238464], ['Indian License.pdf', 'D:\\\\Google Drive Backup\\\\Indian License.pdf', 0.38389843702316284], ['Coop Work Permit.pdf', 'D:\\\\Google Drive Backup\\\\Personal Documents\\\\Coop Work Permit.pdf', 0.3827129006385803]]\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "# Define upload folder\n",
    "UPLOAD_FOLDER = '/content/uploads'\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "search_system = DocumentSearchSystem()\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_file_and_text():\n",
    "    # Get the text data from the request\n",
    "    print(\"Here\")\n",
    "    text = request.form['text']\n",
    "    id = request.form['id']\n",
    "    \n",
    "    if 'file' not in request.files:\n",
    "        # scores = get_file(text)\n",
    "        # print(scores)\n",
    "        print(\"Search id: \" + id + \", Text: \" + text)\n",
    "        results = search_system.search_documents(doc_id=id, query=text)\n",
    "        print(results)\n",
    "        output = {}\n",
    "        i = 1\n",
    "        for r in results:\n",
    "            output[str(i)] = [r[0], r[1], str(r[2])]\n",
    "            i += 1\n",
    "        return jsonify({\"text\": output, \"got_file\": \"true\"}) \n",
    "    else:\n",
    "        file = request.files['file']\n",
    "        path = request.form['path']\n",
    "        # Save the file securely\n",
    "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)\n",
    "        file.save(file_path)\n",
    "    \n",
    "        summary, ocr = generate_summary(file_path, file.filename, text)\n",
    "        #db.save_summary(file.filename, path, summary)\n",
    "        search_system.add_document(\n",
    "                id=id,\n",
    "                file_name=file.filename,\n",
    "                file_path=path,\n",
    "                summary=summary,\n",
    "                ocr=ocr\n",
    "            )\n",
    "        print(\"ID: \" + id + \"Saved: \" + path + \",\" + summary)\n",
    "    \n",
    "        # Clean up: Delete the temporary file\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "        \n",
    "        # Return a response with the text and file path (for example purposes)\n",
    "        output = {\"text\": \"Saved: \" + path, \"file_saved\": file_path}\n",
    "        return jsonify(output)\n",
    "        # if use_internet:\n",
    "        #     output = online_jarvis.search(text)\n",
    "        #     print(\"Internet: \"+ output)\n",
    "        #     return jsonify({\"text\": output})\n",
    "    # print(output[0])\n",
    "    # return jsonify({\"text\": output[0]})\n",
    "            \n",
    "\n",
    "@app.route('/download', methods=['GET'])\n",
    "def download_file():\n",
    "    # Get the filename from the query parameters\n",
    "    filename = request.args.get('filename')\n",
    "    \n",
    "    # Construct the full path\n",
    "    file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(file_path):\n",
    "        abort(404)  # Return 404 if the file is not found\n",
    "\n",
    "    # Send the file as an attachment\n",
    "    return send_file(file_path, as_attachment=True)\n",
    "\n",
    "app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2c6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
